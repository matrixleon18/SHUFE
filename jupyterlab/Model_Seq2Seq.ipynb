{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7635ca9d-4939-4a35-a263-2feced7b671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 LSTM 做一个 Seq2Seq 的预测，不考虑准确性\n",
    "## Architecture \n",
    "## General:        [x1, x2, ... , xn]   ==> [Seq2Seq Model] ==> [Prediction1, Prediction2] \n",
    "## Genral Data:    [122-D, ... , 122-D] ==> [Seq2Seq Model] ==> [1-D, 1-D] \n",
    "## Detail :        [x1, x2, ... , xn]   ==> [Encoder] ==> [h_n, c_n] + [xn]    ==> [Decoder] ==> [Prediont1, Prediction2]\n",
    "## Detail Data:    [122-D, ...., 122-D] ==> [Encoder] ==> [h_n, c_n] + [122-D] ==> [Decoder] ==> [1-D, 1-D]\n",
    "## Decoder :       xn, [h_n, c_n] ==> FC(xn), [h_n, c_n] ==> [1-D, h_n, c_n] ==> LSTM(1-D, h_n, c_n) ==> pred1, h1, c1 ==> LSTM(pred1, h, c) ==> pred2, h2, c2 ==> LSTM..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3fb6d43-f680-43cf-a074-a7cba41af8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_data shape: (441, 60, 130)\n",
      "seq count: 441\n",
      "seq length: 60\n",
      "total batch count: 55\n",
      "batch size: 8\n",
      "train_x: torch.Size([55, 8, 60, 128])\n",
      "train_y: torch.Size([55, 8, 2, 1])\n",
      "test_x:  torch.Size([1, 8, 60, 128])\n",
      "test_y:  torch.Size([1, 8, 2, 1])\n",
      "train_batch_count: 55\n",
      "test_batch_count:  1\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置 GPU 优先\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv(\"601229.csv\", index_col=0)\n",
    "dataset = dataset.drop(['date'], axis=1)\n",
    "# print(dataset.columns)\n",
    "# print(dataset.tail())\n",
    "dataset.insert(1, 'future2',dataset.future)\n",
    "dataset['future2'] = dataset['future'].shift(-1)\n",
    "dataset = dataset.fillna(0)\n",
    "\n",
    "# print(dataset.shape)\n",
    "# print(dataset.tail())\n",
    "\n",
    "\n",
    "# 将数据按照BATCH_SIZE的窗口进行滑动，每个窗口数据做一组\n",
    "# # 数据转成sequence的格式，这里定义每个seq的长度\n",
    "SEQ_LENGTH = 60\n",
    "BATCH_SIZE = 8                                                    # 注意：BATCH_SIZE是要能够整除seq_count的\n",
    "TEST_BATCH_COUNT = 1\n",
    "Y_SEQ_LEN = 2                                                         # 要用2个y来表示预测的第一天和预测的第二天，对应 \"future\" 和 \"future2\",每个y都是1-D的，y的seq_len是2\n",
    "Y_DIM = 1\n",
    "X_DIM = dataset.shape[1]-Y_SEQ_LEN                                    # 表示输入的sequence里每个element有122维度，也是encoder的input_dim\n",
    "\n",
    "# 把数据切换成 BATCH_SIZE 的一个个batch\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                   # 数据一共是 seq_count x seq_len x (x_in_dim+Y_SEQ_LEN) \n",
    "\n",
    "print(\"rolling_data shape: {}\".format(rolling_data.shape))\n",
    "print(\"seq count: {}\".format(rolling_data.shape[0]))                                       # 所以一共有 seq_count 列数据，每一行的数据是123维 （包括y）\n",
    "print(\"seq length: {}\".format(SEQ_LENGTH))\n",
    "\n",
    "\n",
    "total_batch_count = int(rolling_data.shape[0]/BATCH_SIZE)                                   # 把数据规划成 batch_count 个 batch\n",
    "\n",
    "\n",
    "print(\"total batch count: {}\".format(total_batch_count))\n",
    "print(\"batch size: {}\".format(BATCH_SIZE))\n",
    "\n",
    "# rolling_data = rolling_data.reshape(total_batch_count, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)  # 把数据转成 total_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "# rolling_data = torch.tensor(rolling_data)\n",
    "# print(\"rolling_data: {}\".format(rolling_data.shape))\n",
    "# train_batch_count = int((rolling_data.shape[0]-1)/BATCH_SIZE)\n",
    "# test_batch_count = 1\n",
    "\n",
    "train = rolling_data[:-1].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)  # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "test  = rolling_data[-BATCH_SIZE:].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)  # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "train = torch.tensor(train)\n",
    "test  = torch.tensor(test)\n",
    "\n",
    "# train = rolling_data[:train_batch_count, :, :, :]\n",
    "# test  = rolling_data[train_batch_count:, :, :, :]\n",
    "\n",
    "train_x, train_y = train[:,:,:,Y_SEQ_LEN:], train[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "test_x,  test_y  = test[:,:,:, Y_SEQ_LEN:],  test[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "\n",
    "train_y = train_y.permute(0, 1, 3, 2)                                    # conver from [train_batch_count, batch_size, seq_length, y_seq_len]  to [train_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "test_y  =  test_y.permute(0, 1, 3, 2)                                    # conver from [test_batch_count, batch_size, seq_length, y_seq_len]  to  [test_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"test_x:  {}\".format(test_x.shape))\n",
    "print(\"test_y:  {}\".format(test_y.shape))\n",
    "print(\"train_batch_count: {}\".format(train.shape[0]))\n",
    "print(\"test_batch_count:  {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac5928d-7984-49aa-b1ae-57e902a703f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Encoder & Decoder class\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size = self.hidden_dim, num_layers=self.num_layers, batch_first=True, dropout=dropout)\n",
    "        # print(\"Encoder self.input_dim  : {}\".format(self.input_dim))\n",
    "        # print(\"Encoder self.hidden_dim  : {}\".format(self.hidden_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(\"Encoder forward() x: {}\".format(x.shape))\n",
    "        outputs, (h_n, c_n) = self.lstm(x)\n",
    "        # print(\"Encoder outputs :{}\".format(outputs.shape))\n",
    "        # print(\"Encoder h_n     :{}\".format(h_n.shape))\n",
    "        # print(\"Encoder c_n     :{}\".format(c_n.shape))\n",
    "        return outputs, h_n, c_n\n",
    "\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.fc_in = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=self.hidden_dim, hidden_size=self.hidden_dim, num_layers=self.num_layers, batch_first=True, dropout=dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        # input : input batch data, size(input): [batch_size, feature_size]\n",
    "        # notice input only has two dimensions since the input is batchs\n",
    "        # of last coordinate of observed trajectory so the sequence length has been removed.\n",
    "        \n",
    "        # add sequence dimension to input, to allow use of nn.LSTM\n",
    "        # print(\"Decoder forward() input size : {}\".format(input.shape))\n",
    "        # print(\"Decoder forward() hidden size: {}\".format(hidden.shape))\n",
    "        # print(\"Decoder forward() cell size  : {}\".format(cell.shape))\n",
    "        \n",
    "        input = self.fc_in(input)\n",
    "\n",
    "        lstm_output, (hidden, cell) = self.lstm(input, (hidden, cell))\n",
    "        \n",
    "        # print(\"Decoder forward() lstm_output: {}\".format(lstm_output.shape))\n",
    "        \n",
    "        prediction = self.fc_out(lstm_output)         # prediction is [batch_size, output_dim]\n",
    "        \n",
    "        return prediction, hidden, cell\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b80326ab-dd8a-4bdb-96e4-a3480314b501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class\n",
    "\n",
    "DEC_INPUT_DIM   = 1\n",
    "HIDDEN_DIM      = 768\n",
    "NUM_LAYERS      = 5\n",
    "ENC_DROPOUT     = 0.5\n",
    "DEC_DROPOUT     = 0.5\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "        self.decoder_fc_init= nn.Linear(encoder.input_dim, decoder.input_dim)\n",
    "        # self.decoder_fc_input= nn.Linear(decoder.output_dim, decoder.input_dim)\n",
    "        \n",
    "        assert (encoder.hidden_dim == decoder.hidden_dim), \"hidden dimension in encoder and decoder must be equal\"       \n",
    "        assert (encoder.num_layers == decoder.num_layers), \"hidden layer numbers in encoder and decoder must be equal\"\n",
    "        \n",
    "            \n",
    "    def forward(self, x, y, teacher_forcing_ratio = 0.5):\n",
    "        # x is the input to the encoder.\n",
    "        # y is the output from the decoder\n",
    "        # x = [batch size, encoder_in_sequence_len,  encoder_in_dim]               encoder_in_sequence_len=60, encoder_in_dim=122\n",
    "        # y = [batch size, decoder_out_sequence_len, decoder_out_dim]              decoder_out_sequence_len=2, decoder_out_dim=1    \n",
    "        # print(\"Seq2Seq forwar() x shape : {}\".format(x.shape))\n",
    "        # print(\"Seq2Seq forwar() y shape : {}\".format(y.shape))\n",
    "\n",
    "        decoder_out_seq_len = y.shape[1]                                                     # This is most important that define the output length\n",
    "        \n",
    "        # tensor to store decoder outputs of each time step; this outputs will calc loss with y, so its shape is same as y\n",
    "        outputs = torch.zeros(y.shape).to(device)\n",
    "        # print(\"Seq2Seq forward() outputs shape: {}\".format(outputs.shape))\n",
    "        \n",
    "        _, hidden, cell = self.encoder(x)\n",
    "        # print(\"encoder hidden shape: {}\".format(hidden.shape))                            # [encoder_hidden_layer_number, batch_size, encoder_hidden_dim]\n",
    "        # print(\"encoder cell shape :  {}\".format(cell.shape))                              # [encoder_hidden_layer_number, batch_size, encoder_hidden_dim]\n",
    "        \n",
    "        # first input to decoder may be last coordinates of x to predict the future: [last_x]+[h_n,c_n] --> [model] --> [future_y]\n",
    "        decoder_input = x[:, -1, :]                                                           # [batch_size, encoder_input_dim] Get last elements of sequences of the batch from input x\n",
    "        decoder_input = decoder_input.unsqueeze(1)                                            # [batch_size, 1, encoder_input_dim] Get last element of sequence of the batch in encoder\n",
    "        # print(\"decoder_input: {}\".format(decoder_input.shape))\n",
    "        decoder_input = self.decoder_fc_init(decoder_input)                                   # [batch_size, 1, decoder_input_dim] Conver to 1st element of sequence of the batch in decoder\n",
    "        # print(\"decoder_input: {}\".format(decoder_input.shape))\n",
    "        \n",
    "        # Becasue the input and target have different sequence length, Get the target prediction one by one [Prev_prediction]+[h_n,c_n] --> [model] --> [Prediction]\n",
    "        for i in range(decoder_out_seq_len):\n",
    "            # run the decoder for one time step\n",
    "            output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            # print(\"Seq2Seq forward() output shape: {}\".format(output.shape))\n",
    "\n",
    "            # place predictions in a tensor holding predictions for each time step\n",
    "            outputs[:,i,:] = output[:,0]\n",
    "            # print(\"Seq2Seq forward() outputs shape: {}\".format(outputs.shape))            \n",
    "\n",
    "            # assign this prediction as next prediction's input\n",
    "            decoder_input = output\n",
    "            # print(\"Seq2Seq forward() decoder_input shape: {}\".format(output.shape))\n",
    "            \n",
    "            # 或者使用teacher_forcing来优化\n",
    "            teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "            decoder_input = y[:, i, :].unsqueeze(1) if teacher_forcing else output\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f9dd074-51e0-475f-a64c-f817959b185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "encoder = Encoder(input_dim=X_DIM, hidden_dim=HIDDEN_DIM, num_layers=NUM_LAYERS, dropout=ENC_DROPOUT)\n",
    "decoder = Decoder(input_dim=DEC_INPUT_DIM, hidden_dim=HIDDEN_DIM, num_layers=NUM_LAYERS, output_dim=Y_DIM, dropout=DEC_DROPOUT)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder).double().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7692e6fe-3005-40a5-8f3e-01cfaeed148e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 2 epoch loss: 0.461892\n",
      "1 of 2 epoch loss: 0.462579\n"
     ]
    }
   ],
   "source": [
    "# 训练 Seq2Seq 模型; \n",
    "LR = 1e-4\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1, last_epoch=-1)\n",
    "\n",
    "\n",
    "model.train()\n",
    "epoches = 2\n",
    "epoch_loss = 0\n",
    "epoch_loss_list = []\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for step in range(train_x.shape[0]):\n",
    "        pred = model(train_x[step], train_y[step], teacher_forcing_ratio=0.5)\n",
    "        # print(\"Train pred shape : {}\".format(pred.shape))\n",
    "        # print(\"Train train_y[step] shape : {}\".format(train_y[step].shape))\n",
    "        \n",
    "        loss = loss_func(pred, train_y[step].float())              # this calc the last element's loss between prediction and real.\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.data.cpu()\n",
    "\n",
    "    print(\"{} of {} epoch loss: {:.6f}\".format(epoch, epoches, epoch_loss))\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    if (epoch+1)%40 == 0:\n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9aaadf6-8d3d-4488-8ad3-a12104efc196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Loss average:0.000000\n",
      "Prediction: tensor([[-0.0179],\n",
      "        [-0.0199]], device='cuda:0', grad_fn=<SelectBackward0>) ---- Actual: tensor([[0.],\n",
      "        [0.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用模型预测数据\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "\n",
    "for step in range(test_x.shape[0]):\n",
    "    pred = model(test_x[step], test_y[step], teacher_forcing_ratio=0)                       # 测试集上就不要teacher模式了。\n",
    "\n",
    "    loss = loss_func(pred, test_y[step])\n",
    "    \n",
    "    if (step+1) < test_x.shape[0]:                                                         # 最后一个测试数据不需要统计，因为没有真实值。\n",
    "        test_loss += loss.cpu()\n",
    "    \n",
    "    if test_x.shape[0] == 1:\n",
    "        print(\"Prediction Loss average:{:.6f}\".format(test_loss/test_x.shape[0]))\n",
    "    else:\n",
    "        print(\"Prediction Loss average:{:.6f}\".format(test_loss/(test_x.shape[0]-1)))\n",
    "        \n",
    "    print(\"Prediction: {} ---- Actual: {}\".format(pred[-1], test_y[step][-1]))\n",
    "\n",
    "actual_line = test_y[step][:,0,:].cpu().detach().flatten().numpy()\n",
    "pred_line   = pred[:,0,:].cpu().detach().flatten().numpy()\n",
    "plt.plot(actual_line, 'r--')\n",
    "plt.plot(pred_line, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8267f17c-8a01-4949-8287-f3368db264d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
