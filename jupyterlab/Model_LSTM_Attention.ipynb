{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df055ebf-71d4-4fdd-95a3-b391fdfc40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM + Attention 的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15f89b8a-8bf5-4727-a0d3-7affe010d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89fec581-4976-4dbb-b913-899492fc6cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1027)\n",
    "torch.manual_seed(1027)\n",
    "torch.cuda.manual_seed(1027)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcddb16e-5401-44a2-a3e1-1dc4f5f4bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 GPU 优先\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv(\"601229.csv\", index_col=0)\n",
    "dataset = dataset.drop(['date'], axis=1)\n",
    "dataset = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b031b2f1-955b-48e6-932d-af1bf5172b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_data shape: (601, 60, 135)\n",
      "seq count: 601\n",
      "seq length: 60\n",
      "train_x: torch.Size([20, 30, 60, 134])\n",
      "train_y: torch.Size([20, 30, 1, 1])\n",
      "test_x:  torch.Size([1, 1, 60, 134])\n",
      "test_y:  torch.Size([1, 1, 1, 1])\n",
      "train_batch_count: 20\n",
      "test_batch_count:  1\n"
     ]
    }
   ],
   "source": [
    "# 将数据按照BATCH_SIZE的窗口进行滑动，每个窗口数据做一组\n",
    "# # 数据转成sequence的格式，这里定义每个seq的长度\n",
    "SEQ_LENGTH = 60\n",
    "TRAIN_BATCH_SIZE = 30                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_SIZE = 1                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_COUNT = 1\n",
    "Y_SEQ_LEN = 1                                                         # 要用2个y来表示预测的第一天和预测的第二天，对应 \"future\" 和 \"future2\",每个y都是1-D的，y的seq_len是2\n",
    "Y_DIM = 1\n",
    "X_DIM = dataset.shape[1]-Y_SEQ_LEN                                    # 表示输入的sequence里每个element有122维度，也是encoder的input_dim\n",
    "\n",
    "# 把数据切换成 BATCH_SIZE 的一个个batch\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                   # 数据一共是 seq_count x seq_len x (x_in_dim+Y_SEQ_LEN) \n",
    "\n",
    "print(\"rolling_data shape: {}\".format(rolling_data.shape))\n",
    "print(\"seq count: {}\".format(rolling_data.shape[0]))                                       # 所以一共有 seq_count 列数据，每一行的数据是123维 （包括y）\n",
    "print(\"seq length: {}\".format(SEQ_LENGTH))\n",
    "# print(\"batch size: {}\".format(BATCH_SIZE))\n",
    "\n",
    "test_seq_count = TEST_BATCH_COUNT * TEST_BATCH_SIZE\n",
    "\n",
    "\n",
    "# train = rolling_data[:-test_seq_count].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "# test  = rolling_data[-test_seq_count:].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "train = rolling_data[:-test_seq_count].reshape(-1, TRAIN_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                    # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "test  = rolling_data[-test_seq_count:].reshape(-1, TEST_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)      # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "TRAIN_BATCH_SIZE = train.shape[1]\n",
    "TRAIN_BATCH_COUNT = train.shape[0]\n",
    "TEST_BATCH_SIZE = test.shape[1]\n",
    "TEST_BATCH_COUNT = test.shape[0]\n",
    "\n",
    "train = torch.tensor(train)\n",
    "test  = torch.tensor(test)\n",
    "\n",
    "# train = rolling_data[:train_batch_count, :, :, :]\n",
    "# test  = rolling_data[train_batch_count:, :, :, :]\n",
    "\n",
    "train_x, train_y = train[:,:,:,Y_SEQ_LEN:], train[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "test_x,  test_y  = test[:,:,:, Y_SEQ_LEN:],  test[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "\n",
    "train_y = train_y.permute(0, 1, 3, 2)                                    # conver from [train_batch_count, batch_size, seq_length, y_seq_len]  to [train_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "test_y  =  test_y.permute(0, 1, 3, 2)                                    # conver from [test_batch_count, batch_size, seq_length, y_seq_len]  to  [test_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"test_x:  {}\".format(test_x.shape))\n",
    "print(\"test_y:  {}\".format(test_y.shape))\n",
    "print(\"train_batch_count: {}\".format(train.shape[0]))\n",
    "print(\"test_batch_count:  {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2328f7e3-40ed-49ef-890d-4b521c9d8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LSTM 模型\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, attention_size=5, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_layer_size\n",
    "        self.sequence_length = SEQ_LENGTH\n",
    "        self.attention_size = attention_size\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=input_size,        hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_layer_size, hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        self.linear_1 = nn.Linear(hidden_layer_size, int(hidden_layer_size/4))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, output_size)\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # self.h10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)*num_layers).double().to(device)\n",
    "        # self.c10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)*num_layers).double().to(device)\n",
    "        # self.h20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size*num_layers).double().to(device)\n",
    "        # self.c20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size*num_layers).double().to(device)\n",
    "        \n",
    "        self.attention_size = attention_size\n",
    "        # w_omega means W_w\n",
    "        # u_omega means U_w\n",
    "        self.w_omega = Variable(torch.zeros(self.hidden_size, self.attention_size).double().to(device))\n",
    "        self.u_omega = Variable(torch.zeros(self.attention_size).double().to(device))\n",
    "        \n",
    "        self.init_weights2()\n",
    "\n",
    "    def init_weights1(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def init_weights2(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "                \n",
    "    def init_weights3(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "    \n",
    "    \n",
    "    def attention_net(self, lstm_output, query, mask=None):\n",
    "        # print(lstm_output.size())                                                   # [batch_size, squence_length, hidden_dim_size]\n",
    "        # print(query.size())                                                         # [batch_size, squence_length, hidden_dim_size]\n",
    "        d_k = query.size(-1)                                                        # d_k为query的维度\n",
    "        scores = torch.matmul(query, lstm_output.transpose(1, 2)) / math.sqrt(d_k)  #打分机制  scores:[batch_size, seq_len, seq_len]\n",
    "\n",
    "        p_attn = F.softmax(scores, dim = -1)                                        #对最后一个维度归一化得分\n",
    "        context = torch.matmul(p_attn, lstm_output).sum(1)                          #对权重化的x求和，[batch, seq_len, hidden_dim*2]->[batch, hidden_dim*2]\n",
    "        return context, p_attn      \n",
    "        \n",
    "    \n",
    "    def forward(self, x, hidden, cell):\n",
    "\n",
    "        # layer 1\n",
    "        # x = self.linear_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch        \n",
    "        # LSTM layer\n",
    "        # lstm_out, (h_n, c_n) = self.lstm(x, (self.h0.detach(), self.c0.detach()))\n",
    "        \n",
    "        lstm1_out, (h1_n, c1_n) = self.lstm1(x, (hidden, cell))\n",
    "        \n",
    "        lstm1_out = self.dropout(lstm1_out)\n",
    "        \n",
    "        lstm_out, (h2_n, c2_n) = self.lstm2(lstm1_out, (h1_n, c1_n))\n",
    "        \n",
    "        query = self.dropout(lstm_out)\n",
    "\n",
    "        attn_output, attention = self.attention_net(lstm_out, query)       #和LSTM的不同就在于这一句\n",
    "        \n",
    "        predictions = self.linear_2(attn_output)\n",
    "        \n",
    "        return predictions, h2_n, c2_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f33bcc6e-17bd-45ef-a37c-0c4fc5266e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 实例化 LSTM 模型\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "model = LSTMModel(input_size=X_DIM, hidden_layer_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cb343ea-ca72-4aa3-b80e-d67ddab02ca4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 50 epoch loss: 310.0947 with lr: 0.0001\n",
      "1 of 50 epoch loss: 133.4996 with lr: 0.0001\n",
      "2 of 50 epoch loss: 48.6091 with lr: 0.0001\n",
      "3 of 50 epoch loss: 46.0617 with lr: 0.0001\n",
      "4 of 50 epoch loss: 36.2129 with lr: 0.0001\n",
      "5 of 50 epoch loss: 39.1354 with lr: 0.0001\n",
      "6 of 50 epoch loss: 16.2070 with lr: 0.0001\n",
      "7 of 50 epoch loss: 6.6052 with lr: 0.0001\n",
      "8 of 50 epoch loss: 43.1949 with lr: 0.0001\n",
      "9 of 50 epoch loss: 6.0767 with lr: 0.0001\n",
      "10 of 50 epoch loss: 17.5589 with lr: 0.0001\n",
      "11 of 50 epoch loss: 8.8654 with lr: 0.0001\n",
      "12 of 50 epoch loss: 14.9035 with lr: 0.0001\n",
      "13 of 50 epoch loss: 34.9996 with lr: 0.0001\n",
      "14 of 50 epoch loss: 5.6141 with lr: 0.0001\n",
      "15 of 50 epoch loss: 9.3059 with lr: 0.0001\n",
      "16 of 50 epoch loss: 2.9103 with lr: 0.0001\n",
      "17 of 50 epoch loss: 8.3957 with lr: 0.0001\n",
      "18 of 50 epoch loss: 13.8943 with lr: 0.0001\n",
      "19 of 50 epoch loss: 37.8241 with lr: 0.0001\n",
      "20 of 50 epoch loss: 11.6935 with lr: 0.0001\n",
      "21 of 50 epoch loss: 4.5737 with lr: 0.0001\n",
      "22 of 50 epoch loss: 3.8500 with lr: 0.0001\n",
      "23 of 50 epoch loss: 10.6973 with lr: 0.0001\n",
      "24 of 50 epoch loss: 19.9615 with lr: 0.0001\n",
      "25 of 50 epoch loss: 4.7331 with lr: 0.0001\n",
      "26 of 50 epoch loss: 6.2619 with lr: 0.0001\n",
      "27 of 50 epoch loss: 18.7533 with lr: 0.0001\n",
      "28 of 50 epoch loss: 12.1044 with lr: 0.0001\n",
      "29 of 50 epoch loss: 11.4191 with lr: 0.0001\n",
      "30 of 50 epoch loss: 16.1417 with lr: 0.0001\n",
      "31 of 50 epoch loss: 18.4973 with lr: 0.0001\n",
      "32 of 50 epoch loss: 3.2859 with lr: 0.0001\n",
      "33 of 50 epoch loss: 12.8929 with lr: 0.0001\n",
      "34 of 50 epoch loss: 3.7467 with lr: 0.0001\n",
      "35 of 50 epoch loss: 15.5225 with lr: 0.0001\n",
      "36 of 50 epoch loss: 2.2552 with lr: 0.0001\n",
      "37 of 50 epoch loss: 7.4979 with lr: 0.0001\n",
      "38 of 50 epoch loss: 12.7130 with lr: 0.0001\n",
      "39 of 50 epoch loss: 4.9523 with lr: 0.0001\n",
      "40 of 50 epoch loss: 7.7731 with lr: 0.0001\n",
      "41 of 50 epoch loss: 5.2118 with lr: 0.0001\n",
      "42 of 50 epoch loss: 6.2305 with lr: 0.0001\n",
      "43 of 50 epoch loss: 9.9988 with lr: 0.0001\n",
      "44 of 50 epoch loss: 1.9120 with lr: 0.0001\n",
      "45 of 50 epoch loss: 2.3814 with lr: 0.0001\n",
      "46 of 50 epoch loss: 4.2299 with lr: 0.0001\n",
      "47 of 50 epoch loss: 2.7623 with lr: 0.0001\n",
      "48 of 50 epoch loss: 6.5067 with lr: 0.0001\n",
      "49 of 50 epoch loss: 2.2229 with lr: 0.0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练 LSTM 模型;  ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "model.train()\n",
    "LR = 1e-4\n",
    "loss_func = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1, last_epoch=-1)\n",
    "\n",
    "epoches = 50\n",
    "epoch_loss = 0\n",
    "epoch_loss_list = []\n",
    "train_batch_count = train_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for step in range(train_batch_count):\n",
    "        pred, hn, cn = model(train_x[step], h0, c0)\n",
    "        # h0, c0 = hn.detach(), cn.detach()\n",
    "        loss = loss_func(pred[:,-1], train_y[step][:,-1,-1])                # Compare the all sequences' last element in one batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.data.cpu()\n",
    "        \n",
    "    if epoch_loss.item() < 1e-4:\n",
    "        print('Epoch [{}/{}], Loss: {:.5f}'.format(epoch+1, epoches, loss.item()))\n",
    "        print(\"The loss value is reached\")\n",
    "        break\n",
    "\n",
    "    print(\"{} of {} epoch loss: {:.4f} with lr: {}\".format(epoch, epoches, epoch_loss.item(), optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    if (epoch+1) % 2000 ==0:\n",
    "        scheduler.step()\n",
    "    # print(\"learning rate: {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    # for p in optimizer.param_groups:\n",
    "    #     p['lr'] *= 0.99\n",
    "    \n",
    "plt.plot(epoch_loss_list)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d50c0b44-f62f-4c56-90cf-0a55d1fb6d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model, 'e:\\\\Model_LSTM2_ATT.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b617d8d5-f726-4a0a-9ad8-46f2af1e1a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = torch.load('e:\\\\Model_LSTM2_ATT.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "419a5f51-413e-4762-b172-24f2d5dbaad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Loss average:0.457811\n",
      "Prediction: 0.68\n",
      "Actual:     0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用模型预测数据\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_batch_count = test_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TEST_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TEST_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "\n",
    "actual_line=[]\n",
    "pred_line=[]\n",
    "\n",
    "for step in range(test_batch_count):\n",
    "    pred, hn, cn = model(test_x[step], h0, c0)\n",
    "    \n",
    "    h0, c0 = hn.detach(), cn.detach()\n",
    "\n",
    "    loss = loss_func(pred[:,-1], test_y[step][:,-1])                # Compare the all sequences' last element in one batch\n",
    "    \n",
    "    test_loss += loss.cpu()\n",
    "    \n",
    "    actual_line.append(test_y[step][-1,-1].item())\n",
    "    pred_line.append(pred[-1,-1].item())\n",
    "        \n",
    "print(\"Prediction Loss average:{:.6f}\".format(test_loss.data/(step+1)))\n",
    "print(\"Prediction: {:.2f}\".format(float(pred[-1,-1].data)))\n",
    "print(\"Actual:     {:.2f}\".format(float(test_y[step][-1,-1].data)))\n",
    "\n",
    "# actual_line = test_y[step][-1].cpu().detach().flatten().numpy()        # Only plot the last sequence of test batch\n",
    "# pred_line   = pred[-1].cpu().detach().flatten().numpy()                # Only plot the last sequence of test batch\n",
    "plt.plot(actual_line, 'r--')\n",
    "plt.plot(pred_line, 'b-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b83f3b-d110-4968-a685-13beebc4dec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
