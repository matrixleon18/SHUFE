{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df055ebf-71d4-4fdd-95a3-b391fdfc40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 有两层 LSTM 的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5135d3b-bd1e-433f-be46-c48bf8741929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 123)\n",
      "rolling_data shape: (441, 60, 123)\n",
      "seq count: 441\n",
      "seq length: 60\n",
      "total batch count: 49\n",
      "batch size: 9\n",
      "rolling_data: torch.Size([49, 9, 60, 123])\n",
      "train_x: torch.Size([48, 9, 60, 122])\n",
      "train_y: torch.Size([48, 9, 60, 1])\n",
      "test_x:  torch.Size([1, 9, 60, 122])\n",
      "test_y:  torch.Size([1, 9, 60, 1])\n",
      "train_batch_count: 48\n",
      "test_batch_count:  1\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置 GPU 优先\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv(\"601229.csv\", index_col=0)\n",
    "dataset = dataset.drop(['date','prediction'], axis=1)\n",
    "# print(dataset.columns)\n",
    "# print(dataset.tail())\n",
    "dataset['future'] = dataset['future']\n",
    "print(dataset.shape)\n",
    "# print(dataset.tail())\n",
    "\n",
    "\n",
    "# 将数据按照BATCH_SIZE的窗口进行滑动，每个窗口数据做一组\n",
    "# # 数据转成sequence的格式，这里定义每个seq的长度\n",
    "SEQ_LENGTH = 60\n",
    "BATCH_SIZE = 9                                                    # 注意：BATCH_SIZE是要能够整除seq_count的\n",
    "TEST_BATCH_COUNT = 1\n",
    "\n",
    "# 把数据切换成 BATCH_SIZE 的一个个batch\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, dataset.shape[1])                 # 数据一共是 seq_count x seq_len x (in_dim+1)\n",
    "\n",
    "print(\"rolling_data shape: {}\".format(rolling_data.shape))\n",
    "print(\"seq count: {}\".format(rolling_data.shape[0]))                                       # 所以一共有 seq_count 列数据，每一行的数据是123维 （包括y）\n",
    "print(\"seq length: {}\".format(SEQ_LENGTH))\n",
    "\n",
    "\n",
    "total_batch_count = int(rolling_data.shape[0]/BATCH_SIZE)                                   # 把数据规划成 batch_count 个 batch\n",
    "\n",
    "print(\"total batch count: {}\".format(total_batch_count))\n",
    "print(\"batch size: {}\".format(BATCH_SIZE))\n",
    "\n",
    "rolling_data = rolling_data.reshape(total_batch_count, BATCH_SIZE, SEQ_LENGTH, dataset.shape[1])  # 把数据转成 total_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "rolling_data = torch.tensor(rolling_data)\n",
    "print(\"rolling_data: {}\".format(rolling_data.shape))\n",
    "\n",
    "\n",
    "train_batch_count = total_batch_count - TEST_BATCH_COUNT\n",
    "test_batch_count = TEST_BATCH_COUNT\n",
    "\n",
    "train = rolling_data[:train_batch_count, :, :, :]\n",
    "test  = rolling_data[train_batch_count:, :, :, :]\n",
    "\n",
    "train_x, train_y = train[:,:,:,1:], train[:,:,:,0:1]\n",
    "test_x,  test_y  = test[:,:,:, 1:],  test[:,:,:,0:1]\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"test_x:  {}\".format(test_x.shape))\n",
    "print(\"test_y:  {}\".format(test_y.shape))\n",
    "print(\"train_batch_count: {}\".format(train_batch_count))\n",
    "print(\"test_batch_count:  {}\".format(test_batch_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d87b288f-1086-49d4-81ec-2a42bf499c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LSTM 模型\n",
    "np.random.seed(1027)\n",
    "torch.manual_seed(1027)\n",
    "torch.cuda.manual_seed(1027)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TIME_STEP = SEQ_LENGTH                                        # 一般这个单独设定，这里为了简单，还是直接就等于seq_len的方便。其实也就是等于最长的那个sequence length\n",
    "INPUT_SIZE = dataset.shape[1]-1\n",
    "HIDDEN_SIZE = 768\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # self.linear_1 = nn.Linear(input_size, int(hidden_layer_size/4))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=int(hidden_layer_size/2), num_layers=num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=int(hidden_layer_size/2), hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.h10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)).double().to(device)\n",
    "        self.c10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)).double().to(device)\n",
    "        self.h20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        self.c20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        \n",
    "        self.init_weights2()\n",
    "\n",
    "    def init_weights1(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def init_weights2(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "                \n",
    "    def init_weights3(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        # layer 1\n",
    "        # x = self.linear_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch        \n",
    "        # LSTM layer\n",
    "        # lstm_out, (h_n, c_n) = self.lstm(x, (self.h0.detach(), self.c0.detach()))\n",
    "        \n",
    "        lstm1_out, (h1_n, c1_n) = self.lstm1(x, (self.h10, self.c10))\n",
    "        \n",
    "        lstm1_out = self.dropout(lstm1_out)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm2(lstm1_out, (self.h20, self.c20))\n",
    "\n",
    "        # lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "433b3db1-ff6d-4e2b-b54a-5592e85b8de7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get the best loss at 1e-07\n",
      "get the best loss at 1e-06\n",
      "get the best loss at 1e-05\n",
      "get the best loss at 0.0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "model = LSTMModel(input_size=INPUT_SIZE, hidden_layer_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1)\n",
    "model = model.double().to(device)\n",
    "loss_func = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-8)\n",
    "\n",
    "param_lr_list = [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3]\n",
    "param_dropout_list = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "def find_lr(param_lr_list):\n",
    "    mult = 10\n",
    "    lr = param_lr_list[0]\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    best_loss = 0.0\n",
    "    best_lr = 0.0\n",
    "    log_lrs = []\n",
    "    epoch_loss_list = []\n",
    "\n",
    "    for epoch in range(len(param_lr_list)):\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for step in range(train_batch_count): \n",
    "            inputs,labels = train_x[step], train_y[step]\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs[-1], labels[-1][-1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.data.cpu()\n",
    "\n",
    "        if epoch > 1 and epoch_loss > 100 * best_loss:\n",
    "            # print(\"loss is exploding at {}\".format(lr))\n",
    "            # print(\"best loss : {:.2f}\".format(best_loss))\n",
    "            # print(\"epoch loss: {:.2f}\".format(epoch_loss))\n",
    "            # # return log_lrs, losses, epoch_loss_list\n",
    "            # return log_lrs, epoch_loss_list\n",
    "            return best_lr, best_loss\n",
    "\n",
    "        #Record the best loss        \n",
    "        if epoch_loss < best_loss or epoch==1:\n",
    "            print(\"get the best loss at {}\".format(param_lr_list[epoch]))\n",
    "            best_loss = epoch_loss\n",
    "            best_lr = param_lr_list[epoch]\n",
    "        \n",
    "        #Store the values\n",
    "        log_lrs.append(math.log10(param_lr_list[epoch]))\n",
    "        epoch_loss_list.append(epoch_loss)\n",
    "        \n",
    "        \n",
    "        #Update the lr for the next step\n",
    "        for p in optimizer.param_groups:\n",
    "            p['lr'] = param_lr_list[epoch]\n",
    "\n",
    "    plt.plot(log_lrs, epoch_loss_list)\n",
    "    # return log_lrs, epoch_loss_list\n",
    "    return best_lr, best_loss\n",
    "\n",
    "# net = SimpleNeuralNet(28*28,100,10)\n",
    "# optimizer = optim.SGD(net.parameters(),lr=1e-1)\n",
    "# criterion = F.nll_loss\n",
    "\n",
    "lr, loss = find_lr(param_lr_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b20ab-97be-4dbf-8d75-7e4c6054352d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
