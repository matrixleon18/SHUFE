{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df055ebf-71d4-4fdd-95a3-b391fdfc40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 有两层 LSTM 的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39540de0-f3f7-49d4-85fc-8e5b795f8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b46b98e-ca92-437c-baf0-ff836e490e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1027)\n",
    "torch.manual_seed(1027)\n",
    "torch.cuda.manual_seed(1027)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ede11b1-7293-4e58-a48c-d5ccc006a0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 GPU 优先\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv(\"601229.csv\", index_col=0)\n",
    "dataset = dataset.drop(['date'], axis=1)\n",
    "dataset = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4fad15-01d6-4065-ab36-aa952f39cef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_data shape: (601, 60, 135)\n",
      "seq count: 601\n",
      "seq length: 60\n",
      "train_x: torch.Size([6, 100, 60, 134])\n",
      "train_y: torch.Size([6, 100, 1, 1])\n",
      "test_x:  torch.Size([1, 1, 60, 134])\n",
      "test_y:  torch.Size([1, 1, 1, 1])\n",
      "train_batch_count: 6\n",
      "test_batch_count:  1\n"
     ]
    }
   ],
   "source": [
    "# 将数据按照BATCH_SIZE的窗口进行滑动，每个窗口数据做一组\n",
    "# # 数据转成sequence的格式，这里定义每个seq的长度\n",
    "SEQ_LENGTH = 60\n",
    "TRAIN_BATCH_SIZE = 100                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_SIZE = 1                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_COUNT = 1\n",
    "Y_SEQ_LEN = 1                                                         # 要用2个y来表示预测的第一天和预测的第二天，对应 \"future\" 和 \"future2\",每个y都是1-D的，y的seq_len是2\n",
    "Y_DIM = 1\n",
    "X_DIM = dataset.shape[1]-Y_SEQ_LEN                                    # 表示输入的sequence里每个element有122维度，也是encoder的input_dim\n",
    "\n",
    "# 把数据切换成 BATCH_SIZE 的一个个batch\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                   # 数据一共是 seq_count x seq_len x (x_in_dim+Y_SEQ_LEN) \n",
    "\n",
    "print(\"rolling_data shape: {}\".format(rolling_data.shape))\n",
    "print(\"seq count: {}\".format(rolling_data.shape[0]))                                       # 所以一共有 seq_count 列数据，每一行的数据是123维 （包括y）\n",
    "print(\"seq length: {}\".format(SEQ_LENGTH))\n",
    "# print(\"batch size: {}\".format(BATCH_SIZE))\n",
    "\n",
    "test_seq_count = TEST_BATCH_COUNT * TEST_BATCH_SIZE\n",
    "\n",
    "\n",
    "# train = rolling_data[:-test_seq_count].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "# test  = rolling_data[-test_seq_count:].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "train = rolling_data[:-test_seq_count].reshape(-1, TRAIN_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                    # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "test  = rolling_data[-test_seq_count:].reshape(-1, TEST_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)      # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "TRAIN_BATCH_SIZE = train.shape[1]\n",
    "TRAIN_BATCH_COUNT = train.shape[0]\n",
    "TEST_BATCH_SIZE = test.shape[1]\n",
    "TEST_BATCH_COUNT = test.shape[0]\n",
    "\n",
    "train = torch.tensor(train)\n",
    "test  = torch.tensor(test)\n",
    "\n",
    "# train = rolling_data[:train_batch_count, :, :, :]\n",
    "# test  = rolling_data[train_batch_count:, :, :, :]\n",
    "\n",
    "train_x, train_y = train[:,:,:,Y_SEQ_LEN:], train[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "test_x,  test_y  = test[:,:,:, Y_SEQ_LEN:],  test[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "\n",
    "train_y = train_y.permute(0, 1, 3, 2)                                    # conver from [train_batch_count, batch_size, seq_length, y_seq_len]  to [train_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "test_y  =  test_y.permute(0, 1, 3, 2)                                    # conver from [test_batch_count, batch_size, seq_length, y_seq_len]  to  [test_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"test_x:  {}\".format(test_x.shape))\n",
    "print(\"test_y:  {}\".format(test_y.shape))\n",
    "print(\"train_batch_count: {}\".format(train.shape[0]))\n",
    "print(\"test_batch_count:  {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5b7bce-a6af-4fc4-bada-7dd20985f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2-lyaers LSTM class\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(input_size=input_size,        hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.lstm2 = nn.LSTM(input_size=hidden_layer_size, hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "\n",
    "        self.linear_1 = nn.Linear(hidden_layer_size, int(hidden_layer_size/4))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        # self.h10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)).double().to(device)\n",
    "        # self.c10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)).double().to(device)\n",
    "        # self.h20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        # self.c20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        \n",
    "        self.init_weights2()\n",
    "\n",
    "    def init_weights1(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def init_weights2(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "                \n",
    "    def init_weights3(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def forward(self, x, hidden, cell):\n",
    "\n",
    "        # layer 1\n",
    "        # x = self.linear_1(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch        \n",
    "        # LSTM layer\n",
    "        # lstm_out, (h_n, c_n) = self.lstm(x, (self.h0.detach(), self.c0.detach()))\n",
    "        \n",
    "        lstm1_out, (h1_n, c1_n) = self.lstm1(x, (hidden, cell))\n",
    "        \n",
    "        lstm1_out = self.dropout(lstm1_out)\n",
    "        \n",
    "        lstm_out, (h2_n, c2_n) = self.lstm2(lstm1_out, (h1_n, c1_n))\n",
    "\n",
    "        # lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out)\n",
    "        \n",
    "        return predictions, h2_n, c2_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f33bcc6e-17bd-45ef-a37c-0c4fc5266e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 实例化模型\n",
    "HIDDEN_SIZE = 768\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "model = LSTMModel(input_size=X_DIM, hidden_layer_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1).double().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf7392c7-42e8-4345-83a5-1c392716f26e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 200 epoch loss: 0.2118 with lr: 0.0001\n",
      "1 of 200 epoch loss: 0.1056 with lr: 0.0001\n",
      "2 of 200 epoch loss: 0.1238 with lr: 0.0001\n",
      "3 of 200 epoch loss: 0.0717 with lr: 0.0001\n",
      "4 of 200 epoch loss: 0.0588 with lr: 0.0001\n",
      "5 of 200 epoch loss: 0.0525 with lr: 0.0001\n",
      "6 of 200 epoch loss: 0.0492 with lr: 0.0001\n",
      "7 of 200 epoch loss: 0.0489 with lr: 0.0001\n",
      "8 of 200 epoch loss: 0.0462 with lr: 0.0001\n",
      "9 of 200 epoch loss: 0.0484 with lr: 0.0001\n",
      "10 of 200 epoch loss: 0.0466 with lr: 0.0001\n",
      "11 of 200 epoch loss: 0.0472 with lr: 0.0001\n",
      "12 of 200 epoch loss: 0.0458 with lr: 0.0001\n",
      "13 of 200 epoch loss: 0.0444 with lr: 0.0001\n",
      "14 of 200 epoch loss: 0.0453 with lr: 0.0001\n",
      "15 of 200 epoch loss: 0.0449 with lr: 0.0001\n",
      "16 of 200 epoch loss: 0.0446 with lr: 0.0001\n",
      "17 of 200 epoch loss: 0.0451 with lr: 0.0001\n",
      "18 of 200 epoch loss: 0.0444 with lr: 0.0001\n",
      "19 of 200 epoch loss: 0.0440 with lr: 0.0001\n",
      "20 of 200 epoch loss: 0.0427 with lr: 0.0001\n",
      "21 of 200 epoch loss: 0.0438 with lr: 0.0001\n",
      "22 of 200 epoch loss: 0.0427 with lr: 0.0001\n",
      "23 of 200 epoch loss: 0.0430 with lr: 0.0001\n",
      "24 of 200 epoch loss: 0.0445 with lr: 0.0001\n",
      "25 of 200 epoch loss: 0.0424 with lr: 0.0001\n",
      "26 of 200 epoch loss: 0.0415 with lr: 0.0001\n",
      "27 of 200 epoch loss: 0.0406 with lr: 0.0001\n",
      "28 of 200 epoch loss: 0.0421 with lr: 0.0001\n",
      "29 of 200 epoch loss: 0.0419 with lr: 0.0001\n",
      "30 of 200 epoch loss: 0.0448 with lr: 0.0001\n",
      "31 of 200 epoch loss: 0.0425 with lr: 0.0001\n",
      "32 of 200 epoch loss: 0.0416 with lr: 0.0001\n",
      "33 of 200 epoch loss: 0.0420 with lr: 0.0001\n",
      "34 of 200 epoch loss: 0.0415 with lr: 0.0001\n",
      "35 of 200 epoch loss: 0.0455 with lr: 0.0001\n",
      "36 of 200 epoch loss: 0.0456 with lr: 0.0001\n",
      "37 of 200 epoch loss: 0.0452 with lr: 0.0001\n",
      "38 of 200 epoch loss: 0.0413 with lr: 0.0001\n",
      "39 of 200 epoch loss: 0.0417 with lr: 0.0001\n",
      "40 of 200 epoch loss: 0.0402 with lr: 0.0001\n",
      "41 of 200 epoch loss: 0.0401 with lr: 0.0001\n",
      "42 of 200 epoch loss: 0.0412 with lr: 0.0001\n",
      "43 of 200 epoch loss: 0.0390 with lr: 0.0001\n",
      "44 of 200 epoch loss: 0.0399 with lr: 0.0001\n",
      "45 of 200 epoch loss: 0.0419 with lr: 0.0001\n",
      "46 of 200 epoch loss: 0.0397 with lr: 0.0001\n",
      "47 of 200 epoch loss: 0.0407 with lr: 0.0001\n",
      "48 of 200 epoch loss: 0.0384 with lr: 0.0001\n",
      "49 of 200 epoch loss: 0.0402 with lr: 0.0001\n",
      "50 of 200 epoch loss: 0.0394 with lr: 0.0001\n",
      "51 of 200 epoch loss: 0.0397 with lr: 0.0001\n",
      "52 of 200 epoch loss: 0.0371 with lr: 0.0001\n",
      "53 of 200 epoch loss: 0.0394 with lr: 0.0001\n",
      "54 of 200 epoch loss: 0.0385 with lr: 0.0001\n",
      "55 of 200 epoch loss: 0.0392 with lr: 0.0001\n",
      "56 of 200 epoch loss: 0.0382 with lr: 0.0001\n",
      "57 of 200 epoch loss: 0.0422 with lr: 0.0001\n",
      "58 of 200 epoch loss: 0.0373 with lr: 0.0001\n",
      "59 of 200 epoch loss: 0.0388 with lr: 0.0001\n",
      "60 of 200 epoch loss: 0.0395 with lr: 0.0001\n",
      "61 of 200 epoch loss: 0.0370 with lr: 0.0001\n",
      "62 of 200 epoch loss: 0.0394 with lr: 0.0001\n",
      "63 of 200 epoch loss: 0.0386 with lr: 0.0001\n",
      "64 of 200 epoch loss: 0.0392 with lr: 0.0001\n",
      "65 of 200 epoch loss: 0.0369 with lr: 0.0001\n",
      "66 of 200 epoch loss: 0.0394 with lr: 0.0001\n",
      "67 of 200 epoch loss: 0.0385 with lr: 0.0001\n",
      "68 of 200 epoch loss: 0.0381 with lr: 0.0001\n",
      "69 of 200 epoch loss: 0.0378 with lr: 0.0001\n",
      "70 of 200 epoch loss: 0.0363 with lr: 0.0001\n",
      "71 of 200 epoch loss: 0.0363 with lr: 0.0001\n",
      "72 of 200 epoch loss: 0.0371 with lr: 0.0001\n",
      "73 of 200 epoch loss: 0.0366 with lr: 0.0001\n",
      "74 of 200 epoch loss: 0.0365 with lr: 0.0001\n",
      "75 of 200 epoch loss: 0.0388 with lr: 0.0001\n",
      "76 of 200 epoch loss: 0.0387 with lr: 0.0001\n",
      "77 of 200 epoch loss: 0.0358 with lr: 0.0001\n",
      "78 of 200 epoch loss: 0.0379 with lr: 0.0001\n",
      "79 of 200 epoch loss: 0.0369 with lr: 0.0001\n",
      "80 of 200 epoch loss: 0.0345 with lr: 0.0001\n",
      "81 of 200 epoch loss: 0.0357 with lr: 0.0001\n",
      "82 of 200 epoch loss: 0.0355 with lr: 0.0001\n",
      "83 of 200 epoch loss: 0.0364 with lr: 0.0001\n",
      "84 of 200 epoch loss: 0.0364 with lr: 0.0001\n",
      "85 of 200 epoch loss: 0.0342 with lr: 0.0001\n",
      "86 of 200 epoch loss: 0.0342 with lr: 0.0001\n",
      "87 of 200 epoch loss: 0.0340 with lr: 0.0001\n",
      "88 of 200 epoch loss: 0.0346 with lr: 0.0001\n",
      "89 of 200 epoch loss: 0.0355 with lr: 0.0001\n",
      "90 of 200 epoch loss: 0.0354 with lr: 0.0001\n",
      "91 of 200 epoch loss: 0.0361 with lr: 0.0001\n",
      "92 of 200 epoch loss: 0.0334 with lr: 0.0001\n",
      "93 of 200 epoch loss: 0.0362 with lr: 0.0001\n",
      "94 of 200 epoch loss: 0.0352 with lr: 0.0001\n",
      "95 of 200 epoch loss: 0.0357 with lr: 0.0001\n",
      "96 of 200 epoch loss: 0.0345 with lr: 0.0001\n",
      "97 of 200 epoch loss: 0.0328 with lr: 0.0001\n",
      "98 of 200 epoch loss: 0.0343 with lr: 0.0001\n",
      "99 of 200 epoch loss: 0.0335 with lr: 0.0001\n",
      "100 of 200 epoch loss: 0.0331 with lr: 0.0001\n",
      "101 of 200 epoch loss: 0.0338 with lr: 0.0001\n",
      "102 of 200 epoch loss: 0.0328 with lr: 0.0001\n",
      "103 of 200 epoch loss: 0.0326 with lr: 0.0001\n",
      "104 of 200 epoch loss: 0.0333 with lr: 0.0001\n",
      "105 of 200 epoch loss: 0.0321 with lr: 0.0001\n",
      "106 of 200 epoch loss: 0.0329 with lr: 0.0001\n",
      "107 of 200 epoch loss: 0.0329 with lr: 0.0001\n",
      "108 of 200 epoch loss: 0.0332 with lr: 0.0001\n",
      "109 of 200 epoch loss: 0.0338 with lr: 0.0001\n",
      "110 of 200 epoch loss: 0.0328 with lr: 0.0001\n",
      "111 of 200 epoch loss: 0.0333 with lr: 0.0001\n",
      "112 of 200 epoch loss: 0.0346 with lr: 0.0001\n",
      "113 of 200 epoch loss: 0.0314 with lr: 0.0001\n",
      "114 of 200 epoch loss: 0.0325 with lr: 0.0001\n",
      "115 of 200 epoch loss: 0.0328 with lr: 0.0001\n",
      "116 of 200 epoch loss: 0.0339 with lr: 0.0001\n",
      "117 of 200 epoch loss: 0.0315 with lr: 0.0001\n",
      "118 of 200 epoch loss: 0.0309 with lr: 0.0001\n",
      "119 of 200 epoch loss: 0.0311 with lr: 0.0001\n",
      "120 of 200 epoch loss: 0.0328 with lr: 0.0001\n",
      "121 of 200 epoch loss: 0.0299 with lr: 0.0001\n",
      "122 of 200 epoch loss: 0.0303 with lr: 0.0001\n",
      "123 of 200 epoch loss: 0.0303 with lr: 0.0001\n",
      "124 of 200 epoch loss: 0.0290 with lr: 0.0001\n",
      "125 of 200 epoch loss: 0.0300 with lr: 0.0001\n",
      "126 of 200 epoch loss: 0.0294 with lr: 0.0001\n",
      "127 of 200 epoch loss: 0.0287 with lr: 0.0001\n",
      "128 of 200 epoch loss: 0.0302 with lr: 0.0001\n",
      "129 of 200 epoch loss: 0.0315 with lr: 0.0001\n",
      "130 of 200 epoch loss: 0.0331 with lr: 0.0001\n",
      "131 of 200 epoch loss: 0.0318 with lr: 0.0001\n",
      "132 of 200 epoch loss: 0.0317 with lr: 0.0001\n",
      "133 of 200 epoch loss: 0.0293 with lr: 0.0001\n",
      "134 of 200 epoch loss: 0.0291 with lr: 0.0001\n",
      "135 of 200 epoch loss: 0.0309 with lr: 0.0001\n",
      "136 of 200 epoch loss: 0.0288 with lr: 0.0001\n",
      "137 of 200 epoch loss: 0.0301 with lr: 0.0001\n",
      "138 of 200 epoch loss: 0.0294 with lr: 0.0001\n",
      "139 of 200 epoch loss: 0.0288 with lr: 0.0001\n",
      "140 of 200 epoch loss: 0.0298 with lr: 0.0001\n",
      "141 of 200 epoch loss: 0.0308 with lr: 0.0001\n",
      "142 of 200 epoch loss: 0.0261 with lr: 0.0001\n",
      "143 of 200 epoch loss: 0.0297 with lr: 0.0001\n",
      "144 of 200 epoch loss: 0.0291 with lr: 0.0001\n",
      "145 of 200 epoch loss: 0.0296 with lr: 0.0001\n",
      "146 of 200 epoch loss: 0.0300 with lr: 0.0001\n",
      "147 of 200 epoch loss: 0.0277 with lr: 0.0001\n",
      "148 of 200 epoch loss: 0.0278 with lr: 0.0001\n",
      "149 of 200 epoch loss: 0.0264 with lr: 0.0001\n",
      "150 of 200 epoch loss: 0.0285 with lr: 0.0001\n",
      "151 of 200 epoch loss: 0.0268 with lr: 0.0001\n",
      "152 of 200 epoch loss: 0.0290 with lr: 0.0001\n",
      "153 of 200 epoch loss: 0.0279 with lr: 0.0001\n",
      "154 of 200 epoch loss: 0.0277 with lr: 0.0001\n",
      "155 of 200 epoch loss: 0.0265 with lr: 0.0001\n",
      "156 of 200 epoch loss: 0.0269 with lr: 0.0001\n",
      "157 of 200 epoch loss: 0.0263 with lr: 0.0001\n",
      "158 of 200 epoch loss: 0.0279 with lr: 0.0001\n",
      "159 of 200 epoch loss: 0.0265 with lr: 0.0001\n",
      "160 of 200 epoch loss: 0.0277 with lr: 0.0001\n",
      "161 of 200 epoch loss: 0.0266 with lr: 0.0001\n",
      "162 of 200 epoch loss: 0.0285 with lr: 0.0001\n",
      "163 of 200 epoch loss: 0.0266 with lr: 0.0001\n",
      "164 of 200 epoch loss: 0.0273 with lr: 0.0001\n",
      "165 of 200 epoch loss: 0.0270 with lr: 0.0001\n",
      "166 of 200 epoch loss: 0.0284 with lr: 0.0001\n",
      "167 of 200 epoch loss: 0.0268 with lr: 0.0001\n",
      "168 of 200 epoch loss: 0.0270 with lr: 0.0001\n",
      "169 of 200 epoch loss: 0.0277 with lr: 0.0001\n",
      "170 of 200 epoch loss: 0.0253 with lr: 0.0001\n",
      "171 of 200 epoch loss: 0.0252 with lr: 0.0001\n",
      "172 of 200 epoch loss: 0.0259 with lr: 0.0001\n",
      "173 of 200 epoch loss: 0.0258 with lr: 0.0001\n",
      "174 of 200 epoch loss: 0.0236 with lr: 0.0001\n",
      "175 of 200 epoch loss: 0.0240 with lr: 0.0001\n",
      "176 of 200 epoch loss: 0.0255 with lr: 0.0001\n",
      "177 of 200 epoch loss: 0.0259 with lr: 0.0001\n",
      "178 of 200 epoch loss: 0.0254 with lr: 0.0001\n",
      "179 of 200 epoch loss: 0.0230 with lr: 0.0001\n",
      "180 of 200 epoch loss: 0.0245 with lr: 0.0001\n",
      "181 of 200 epoch loss: 0.0255 with lr: 0.0001\n",
      "182 of 200 epoch loss: 0.0244 with lr: 0.0001\n",
      "183 of 200 epoch loss: 0.0252 with lr: 0.0001\n",
      "184 of 200 epoch loss: 0.0261 with lr: 0.0001\n",
      "185 of 200 epoch loss: 0.0245 with lr: 0.0001\n",
      "186 of 200 epoch loss: 0.0238 with lr: 0.0001\n",
      "187 of 200 epoch loss: 0.0258 with lr: 0.0001\n",
      "188 of 200 epoch loss: 0.0249 with lr: 0.0001\n",
      "189 of 200 epoch loss: 0.0247 with lr: 0.0001\n",
      "190 of 200 epoch loss: 0.0232 with lr: 0.0001\n",
      "191 of 200 epoch loss: 0.0248 with lr: 0.0001\n",
      "192 of 200 epoch loss: 0.0233 with lr: 0.0001\n",
      "193 of 200 epoch loss: 0.0231 with lr: 0.0001\n",
      "194 of 200 epoch loss: 0.0225 with lr: 0.0001\n",
      "195 of 200 epoch loss: 0.0229 with lr: 0.0001\n",
      "196 of 200 epoch loss: 0.0222 with lr: 0.0001\n",
      "197 of 200 epoch loss: 0.0238 with lr: 0.0001\n",
      "198 of 200 epoch loss: 0.0228 with lr: 0.0001\n",
      "199 of 200 epoch loss: 0.0233 with lr: 0.0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练 LSTM 模型;  ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "model.train()\n",
    "LR = 1e-4\n",
    "loss_func = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1, last_epoch=-1)\n",
    "\n",
    "epoches = 200\n",
    "epoch_loss = 0\n",
    "epoch_loss_list = []\n",
    "train_batch_count = train_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for step in range(train_batch_count):\n",
    "        pred, hn, cn = model(train_x[step], h0, c0)\n",
    "        h0, c0 = hn.detach(), cn.detach()\n",
    "        loss = loss_func(pred[:,-1], train_y[step][:,-1])                # Compare the all sequences' last element in one batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.data.cpu()\n",
    "        \n",
    "    if epoch_loss.item() < 1e-4:\n",
    "        print('Epoch [{}/{}], Loss: {:.5f}'.format(epoch+1, epoches, loss.item()))\n",
    "        print(\"The loss value is reached\")\n",
    "        break\n",
    "\n",
    "    print(\"{} of {} epoch loss: {:.4f} with lr: {}\".format(epoch, epoches, epoch_loss.item(), optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    if (epoch+1) % 2000 ==0:\n",
    "        scheduler.step()\n",
    "    # print(\"learning rate: {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    # for p in optimizer.param_groups:\n",
    "    #     p['lr'] *= 0.99\n",
    "    \n",
    "plt.plot(epoch_loss_list)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d50c0b44-f62f-4c56-90cf-0a55d1fb6d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model, 'e:\\\\Model_LSTM2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b617d8d5-f726-4a0a-9ad8-46f2af1e1a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = torch.load('e:\\\\Model_LSTM2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c7e16af-8034-49d5-a300-fc2bfd644947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Loss average:0.001083\n",
      "Prediction: -0.03\n",
      "Actual:     0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用模型预测数据\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_batch_count = test_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TEST_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TEST_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "\n",
    "actual_line=[]\n",
    "pred_line=[]\n",
    "\n",
    "for step in range(test_batch_count):\n",
    "    pred, hn, cn = model(test_x[step], h0, c0)\n",
    "    \n",
    "    h0, c0 = hn.detach(), cn.detach()\n",
    "\n",
    "    loss = loss_func(pred[:,-1], test_y[step][:,-1])                # Compare the all sequences' last element in one batch\n",
    "    \n",
    "    test_loss += loss.cpu()\n",
    "    \n",
    "    actual_line.append(test_y[step][-1,-1].item())\n",
    "    pred_line.append(pred[-1,-1].item())\n",
    "        \n",
    "print(\"Prediction Loss average:{:.6f}\".format(test_loss.data/(step+1)))\n",
    "print(\"Prediction: {:.2f}\".format(float(pred[-1,-1].data)))\n",
    "print(\"Actual:     {:.2f}\".format(float(test_y[step][-1,-1].data)))\n",
    "\n",
    "# actual_line = test_y[step][-1].cpu().detach().flatten().numpy()        # Only plot the last sequence of test batch\n",
    "# pred_line   = pred[-1].cpu().detach().flatten().numpy()                # Only plot the last sequence of test batch\n",
    "plt.plot(actual_line, 'r--')\n",
    "plt.plot(pred_line, 'b-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b83f3b-d110-4968-a685-13beebc4dec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
