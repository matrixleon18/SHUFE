{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df055ebf-71d4-4fdd-95a3-b391fdfc40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 有两层 LSTM 的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf2f70f0-3a72-4250-8005-9dffb5f17e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_data shape: (441, 60, 129)\n",
      "seq count: 441\n",
      "seq length: 60\n",
      "batch size: 440\n",
      "train_x: torch.Size([1, 440, 60, 128])\n",
      "train_y: torch.Size([1, 440, 1, 1])\n",
      "test_x:  torch.Size([1, 440, 60, 128])\n",
      "test_y:  torch.Size([1, 440, 1, 1])\n",
      "train_batch_count: 1\n",
      "test_batch_count:  1\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置 GPU 优先\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv(\"601229.csv\", index_col=0)\n",
    "dataset = dataset.drop(['date'], axis=1)\n",
    "# print(dataset.columns)\n",
    "# print(dataset.tail())\n",
    "dataset = dataset.fillna(0)\n",
    "\n",
    "# print(dataset.shape)\n",
    "# print(dataset.tail())\n",
    "\n",
    "\n",
    "# 将数据按照BATCH_SIZE的窗口进行滑动，每个窗口数据做一组\n",
    "# # 数据转成sequence的格式，这里定义每个seq的长度\n",
    "SEQ_LENGTH = 60\n",
    "BATCH_SIZE = 440                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_COUNT = 1\n",
    "Y_SEQ_LEN = 1                                                         # 要用2个y来表示预测的第一天和预测的第二天，对应 \"future\" 和 \"future2\",每个y都是1-D的，y的seq_len是2\n",
    "Y_DIM = 1\n",
    "X_DIM = dataset.shape[1]-Y_SEQ_LEN                                    # 表示输入的sequence里每个element有122维度，也是encoder的input_dim\n",
    "\n",
    "# 把数据切换成 BATCH_SIZE 的一个个batch\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                   # 数据一共是 seq_count x seq_len x (x_in_dim+Y_SEQ_LEN) \n",
    "\n",
    "print(\"rolling_data shape: {}\".format(rolling_data.shape))\n",
    "print(\"seq count: {}\".format(rolling_data.shape[0]))                                       # 所以一共有 seq_count 列数据，每一行的数据是123维 （包括y）\n",
    "print(\"seq length: {}\".format(SEQ_LENGTH))\n",
    "print(\"batch size: {}\".format(BATCH_SIZE))\n",
    "\n",
    "\n",
    "train = rolling_data[:-1].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "test  = rolling_data[-BATCH_SIZE:].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)  # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "train = torch.tensor(train)\n",
    "test  = torch.tensor(test)\n",
    "\n",
    "# train = rolling_data[:train_batch_count, :, :, :]\n",
    "# test  = rolling_data[train_batch_count:, :, :, :]\n",
    "\n",
    "train_x, train_y = train[:,:,:,Y_SEQ_LEN:], train[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "test_x,  test_y  = test[:,:,:, Y_SEQ_LEN:],  test[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "\n",
    "train_y = train_y.permute(0, 1, 3, 2)                                    # conver from [train_batch_count, batch_size, seq_length, y_seq_len]  to [train_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "test_y  =  test_y.permute(0, 1, 3, 2)                                    # conver from [test_batch_count, batch_size, seq_length, y_seq_len]  to  [test_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"test_x:  {}\".format(test_x.shape))\n",
    "print(\"test_y:  {}\".format(test_y.shape))\n",
    "print(\"train_batch_count: {}\".format(train.shape[0]))\n",
    "print(\"test_batch_count:  {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2328f7e3-40ed-49ef-890d-4b521c9d8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LSTM 模型\n",
    "np.random.seed(1027)\n",
    "torch.manual_seed(1027)\n",
    "torch.cuda.manual_seed(1027)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TIME_STEP = SEQ_LENGTH                                        # 一般这个单独设定，这里为了简单，还是直接就等于seq_len的方便。其实也就是等于最长的那个sequence length\n",
    "HIDDEN_SIZE = 768\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=int(hidden_layer_size/2), num_layers=num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=int(hidden_layer_size/2), hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear_1 = nn.Linear(hidden_layer_size, int(hidden_layer_size/4))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.h10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)).double().to(device)\n",
    "        self.c10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)).double().to(device)\n",
    "        self.h20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        self.c20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        \n",
    "        self.init_weights2()\n",
    "\n",
    "    def init_weights1(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def init_weights2(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "                \n",
    "    def init_weights3(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def forward(self, x):\n",
    "\n",
    "        # layer 1\n",
    "        # x = self.linear_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch        \n",
    "        # LSTM layer\n",
    "        # lstm_out, (h_n, c_n) = self.lstm(x, (self.h0.detach(), self.c0.detach()))\n",
    "        \n",
    "        lstm1_out, (h1_n, c1_n) = self.lstm1(x, (self.h10, self.c10))\n",
    "        \n",
    "        lstm1_out = self.dropout(lstm1_out)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm2(lstm1_out, (self.h20, self.c20))\n",
    "\n",
    "        # lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d87b288f-1086-49d4-81ec-2a42bf499c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LSTM 模型\n",
    "np.random.seed(1027)\n",
    "torch.manual_seed(1027)\n",
    "torch.cuda.manual_seed(1027)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "TIME_STEP = SEQ_LENGTH                                        # 一般这个单独设定，这里为了简单，还是直接就等于seq_len的方便。其实也就是等于最长的那个sequence length\n",
    "HIDDEN_SIZE = 768\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.lstm1 = nn.LSTM(input_size=input_size, hidden_size=int(hidden_layer_size/2), num_layers=num_layers, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=int(hidden_layer_size/2), hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True)\n",
    "        self.linear_1 = nn.Linear(hidden_layer_size, int(hidden_layer_size/4))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.h10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)).double().to(device)\n",
    "        self.c10 = torch.zeros(NUM_LAYERS, BATCH_SIZE, int(hidden_layer_size/2)).double().to(device)\n",
    "        self.h20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        self.c20 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        \n",
    "        self.init_weights2()\n",
    "\n",
    "    def init_weights1(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def init_weights2(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "                \n",
    "    def init_weights3(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def forward(self, x):\n",
    "\n",
    "        # layer 1\n",
    "        # x = self.linear_1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch        \n",
    "        # LSTM layer\n",
    "        # lstm_out, (h_n, c_n) = self.lstm(x, (self.h0.detach(), self.c0.detach()))\n",
    "        \n",
    "        lstm1_out, (h1_n, c1_n) = self.lstm1(x, (self.h10, self.c10))\n",
    "        \n",
    "        lstm1_out = self.dropout(lstm1_out)\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm2(lstm1_out, (self.h20, self.c20))\n",
    "\n",
    "        # lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f33bcc6e-17bd-45ef-a37c-0c4fc5266e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 实例化 LSTM 模型\n",
    "model = LSTMModel(input_size=X_DIM, hidden_layer_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1)\n",
    "model = model.double().to(device)\n",
    "LR = 1e-4\n",
    "loss_func = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7c81486-f58a-4a42-b0ba-176f469dbaa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 100 epoch loss: 0.0101 with lr: 0.0001\n",
      "1 of 100 epoch loss: 0.0633 with lr: 0.0001\n",
      "2 of 100 epoch loss: 0.0111 with lr: 0.0001\n",
      "3 of 100 epoch loss: 0.0198 with lr: 0.0001\n",
      "4 of 100 epoch loss: 0.0300 with lr: 0.0001\n",
      "5 of 100 epoch loss: 0.0211 with lr: 0.0001\n",
      "6 of 100 epoch loss: 0.0104 with lr: 0.0001\n",
      "7 of 100 epoch loss: 0.0083 with lr: 0.0001\n",
      "8 of 100 epoch loss: 0.0127 with lr: 0.0001\n",
      "9 of 100 epoch loss: 0.0154 with lr: 0.0001\n",
      "10 of 100 epoch loss: 0.0142 with lr: 0.0001\n",
      "11 of 100 epoch loss: 0.0105 with lr: 0.0001\n",
      "12 of 100 epoch loss: 0.0082 with lr: 0.0001\n",
      "13 of 100 epoch loss: 0.0084 with lr: 0.0001\n",
      "14 of 100 epoch loss: 0.0098 with lr: 0.0001\n",
      "15 of 100 epoch loss: 0.0108 with lr: 0.0001\n",
      "16 of 100 epoch loss: 0.0104 with lr: 0.0001\n",
      "17 of 100 epoch loss: 0.0094 with lr: 0.0001\n",
      "18 of 100 epoch loss: 0.0081 with lr: 0.0001\n",
      "19 of 100 epoch loss: 0.0078 with lr: 0.0001\n",
      "20 of 100 epoch loss: 0.0080 with lr: 0.0001\n",
      "21 of 100 epoch loss: 0.0085 with lr: 0.0001\n",
      "22 of 100 epoch loss: 0.0088 with lr: 0.0001\n",
      "23 of 100 epoch loss: 0.0086 with lr: 0.0001\n",
      "24 of 100 epoch loss: 0.0082 with lr: 0.0001\n",
      "25 of 100 epoch loss: 0.0079 with lr: 0.0001\n",
      "26 of 100 epoch loss: 0.0077 with lr: 0.0001\n",
      "27 of 100 epoch loss: 0.0076 with lr: 0.0001\n",
      "28 of 100 epoch loss: 0.0077 with lr: 0.0001\n",
      "29 of 100 epoch loss: 0.0079 with lr: 0.0001\n",
      "30 of 100 epoch loss: 0.0078 with lr: 0.0001\n",
      "31 of 100 epoch loss: 0.0077 with lr: 0.0001\n",
      "32 of 100 epoch loss: 0.0074 with lr: 0.0001\n",
      "33 of 100 epoch loss: 0.0073 with lr: 0.0001\n",
      "34 of 100 epoch loss: 0.0073 with lr: 0.0001\n",
      "35 of 100 epoch loss: 0.0073 with lr: 0.0001\n",
      "36 of 100 epoch loss: 0.0074 with lr: 0.0001\n",
      "37 of 100 epoch loss: 0.0073 with lr: 0.0001\n",
      "38 of 100 epoch loss: 0.0074 with lr: 0.0001\n",
      "39 of 100 epoch loss: 0.0072 with lr: 0.0001\n",
      "40 of 100 epoch loss: 0.0071 with lr: 0.0001\n",
      "41 of 100 epoch loss: 0.0070 with lr: 0.0001\n",
      "42 of 100 epoch loss: 0.0072 with lr: 0.0001\n",
      "43 of 100 epoch loss: 0.0072 with lr: 0.0001\n",
      "44 of 100 epoch loss: 0.0070 with lr: 0.0001\n",
      "45 of 100 epoch loss: 0.0071 with lr: 0.0001\n",
      "46 of 100 epoch loss: 0.0070 with lr: 0.0001\n",
      "47 of 100 epoch loss: 0.0070 with lr: 0.0001\n",
      "48 of 100 epoch loss: 0.0069 with lr: 0.0001\n",
      "49 of 100 epoch loss: 0.0069 with lr: 0.0001\n",
      "50 of 100 epoch loss: 0.0067 with lr: 0.0001\n",
      "51 of 100 epoch loss: 0.0070 with lr: 0.0001\n",
      "52 of 100 epoch loss: 0.0069 with lr: 0.0001\n",
      "53 of 100 epoch loss: 0.0067 with lr: 0.0001\n",
      "54 of 100 epoch loss: 0.0069 with lr: 0.0001\n",
      "55 of 100 epoch loss: 0.0067 with lr: 0.0001\n",
      "56 of 100 epoch loss: 0.0068 with lr: 0.0001\n",
      "57 of 100 epoch loss: 0.0067 with lr: 0.0001\n",
      "58 of 100 epoch loss: 0.0068 with lr: 0.0001\n",
      "59 of 100 epoch loss: 0.0067 with lr: 0.0001\n",
      "60 of 100 epoch loss: 0.0067 with lr: 0.0001\n",
      "61 of 100 epoch loss: 0.0066 with lr: 0.0001\n",
      "62 of 100 epoch loss: 0.0067 with lr: 0.0001\n",
      "63 of 100 epoch loss: 0.0067 with lr: 0.0001\n",
      "64 of 100 epoch loss: 0.0066 with lr: 0.0001\n",
      "65 of 100 epoch loss: 0.0066 with lr: 0.0001\n",
      "66 of 100 epoch loss: 0.0065 with lr: 0.0001\n",
      "67 of 100 epoch loss: 0.0066 with lr: 0.0001\n",
      "68 of 100 epoch loss: 0.0065 with lr: 0.0001\n",
      "69 of 100 epoch loss: 0.0065 with lr: 0.0001\n",
      "70 of 100 epoch loss: 0.0066 with lr: 0.0001\n",
      "71 of 100 epoch loss: 0.0065 with lr: 0.0001\n",
      "72 of 100 epoch loss: 0.0065 with lr: 0.0001\n",
      "73 of 100 epoch loss: 0.0065 with lr: 0.0001\n",
      "74 of 100 epoch loss: 0.0064 with lr: 0.0001\n",
      "75 of 100 epoch loss: 0.0066 with lr: 0.0001\n",
      "76 of 100 epoch loss: 0.0064 with lr: 0.0001\n",
      "77 of 100 epoch loss: 0.0065 with lr: 0.0001\n",
      "78 of 100 epoch loss: 0.0064 with lr: 0.0001\n",
      "79 of 100 epoch loss: 0.0063 with lr: 0.0001\n",
      "80 of 100 epoch loss: 0.0063 with lr: 0.0001\n",
      "81 of 100 epoch loss: 0.0063 with lr: 0.0001\n",
      "82 of 100 epoch loss: 0.0062 with lr: 0.0001\n",
      "83 of 100 epoch loss: 0.0065 with lr: 0.0001\n",
      "84 of 100 epoch loss: 0.0064 with lr: 0.0001\n",
      "85 of 100 epoch loss: 0.0063 with lr: 0.0001\n",
      "86 of 100 epoch loss: 0.0062 with lr: 0.0001\n",
      "87 of 100 epoch loss: 0.0063 with lr: 0.0001\n",
      "88 of 100 epoch loss: 0.0062 with lr: 0.0001\n",
      "89 of 100 epoch loss: 0.0064 with lr: 0.0001\n",
      "90 of 100 epoch loss: 0.0064 with lr: 0.0001\n",
      "91 of 100 epoch loss: 0.0062 with lr: 0.0001\n",
      "92 of 100 epoch loss: 0.0064 with lr: 0.0001\n",
      "93 of 100 epoch loss: 0.0061 with lr: 0.0001\n",
      "94 of 100 epoch loss: 0.0062 with lr: 0.0001\n",
      "95 of 100 epoch loss: 0.0060 with lr: 0.0001\n",
      "96 of 100 epoch loss: 0.0062 with lr: 0.0001\n",
      "97 of 100 epoch loss: 0.0061 with lr: 0.0001\n",
      "98 of 100 epoch loss: 0.0062 with lr: 0.0001\n",
      "99 of 100 epoch loss: 0.0062 with lr: 0.0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练 LSTM 模型;  ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "model.train()\n",
    "epoches = 100\n",
    "epoch_loss = 0\n",
    "epoch_loss_list = []\n",
    "train_batch_count = train_x.shape[0]\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for step in range(train_batch_count):\n",
    "        pred = model(train_x[step])\n",
    "        loss = loss_func(pred[:,-1], train_y[step][:,-1])                # Compare the all sequences' last element in one batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.data.cpu()\n",
    "        \n",
    "    if epoch_loss.item() < 1e-4:\n",
    "        print('Epoch [{}/{}], Loss: {:.5f}'.format(epoch+1, epoches, loss.item()))\n",
    "        print(\"The loss value is reached\")\n",
    "        break\n",
    "\n",
    "    print(\"{} of {} epoch loss: {:.4f} with lr: {}\".format(epoch, epoches, epoch_loss.item(), optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    if (epoch+1) % 50 ==0:\n",
    "        scheduler.step()\n",
    "    # print(\"learning rate: {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    # for p in optimizer.param_groups:\n",
    "    #     p['lr'] *= 0.99\n",
    "    \n",
    "plt.plot(epoch_loss_list)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d50c0b44-f62f-4c56-90cf-0a55d1fb6d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model, 'e:\\\\Model_LSTM2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b617d8d5-f726-4a0a-9ad8-46f2af1e1a12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = torch.load('e:\\\\Model_LSTM2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76b4797e-cea6-470f-8cdc-1133bc9de018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([440, 60, 1])\n",
      "torch.Size([1])\n",
      "torch.Size([1])\n",
      "torch.Size([440, 1, 1])\n",
      "Prediction Loss average:0.002396\n",
      "Prediction: -0.05\n",
      "Actual:     0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用模型预测数据\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_batch_count = test_x.shape[0]\n",
    "\n",
    "for step in range(test_batch_count):\n",
    "    pred = model(test_x[step])\n",
    "\n",
    "    loss = loss_func(pred[-1,-1], test_y[step][-1,-1])                # Compare the all sequences' last element in one batch\n",
    "    \n",
    "    test_loss += loss.cpu()\n",
    "    \n",
    "print(\"Prediction Loss average:{:.6f}\".format(test_loss.data/(step+1)))\n",
    "print(\"Prediction: {:.2f}\".format(float(pred[-1,-1].data)))\n",
    "print(\"Actual:     {:.2f}\".format(float(test_y[step][-1,-1].data)))\n",
    "\n",
    "actual_line = test_y[step][-1].cpu().detach().flatten().numpy()        # Only plot the last sequence of test batch\n",
    "pred_line   = pred[-1].cpu().detach().flatten().numpy()                # Only plot the last sequence of test batch\n",
    "plt.plot(actual_line, 'r--')\n",
    "plt.plot(pred_line, 'b-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b83f3b-d110-4968-a685-13beebc4dec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
