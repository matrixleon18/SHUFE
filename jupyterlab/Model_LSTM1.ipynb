{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6e9707-a755-443b-8483-00b9df2ea38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 单层 LSTM 的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301a0bfe-88e2-4398-9334-cc77d8bb8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0c3f73-0613-4605-9691-ba3dfbbfbf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1027)\n",
    "torch.manual_seed(1027)\n",
    "torch.cuda.manual_seed(1027)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe160cab-111b-4904-abb0-8204a8a10669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 GPU 优先\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv(\"601229.csv\", index_col=0)\n",
    "dataset = dataset.drop(['date'], axis=1)\n",
    "dataset = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de255091-c7b4-4495-a035-b80b06317681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_data shape: (601, 60, 139)\n",
      "seq count: 601\n",
      "seq length: 60\n",
      "train_x: torch.Size([6, 100, 60, 138])\n",
      "train_y: torch.Size([6, 100, 1, 1])\n",
      "test_x:  torch.Size([1, 1, 60, 138])\n",
      "test_y:  torch.Size([1, 1, 1, 1])\n",
      "train_batch_count: 6\n",
      "test_batch_count:  1\n"
     ]
    }
   ],
   "source": [
    "# 将数据按照BATCH_SIZE的窗口进行滑动，每个窗口数据做一组\n",
    "# # 数据转成sequence的格式，这里定义每个seq的长度\n",
    "SEQ_LENGTH = 60\n",
    "TRAIN_BATCH_SIZE = 100                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_SIZE = 1                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_COUNT = 1\n",
    "Y_SEQ_LEN = 1                                                         # 要用2个y来表示预测的第一天和预测的第二天，对应 \"future\" 和 \"future2\",每个y都是1-D的，y的seq_len是2\n",
    "Y_DIM = 1\n",
    "X_DIM = dataset.shape[1]-Y_SEQ_LEN                                    # 表示输入的sequence里每个element有122维度，也是encoder的input_dim\n",
    "\n",
    "# 把数据切换成 BATCH_SIZE 的一个个batch\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                   # 数据一共是 seq_count x seq_len x (x_in_dim+Y_SEQ_LEN) \n",
    "\n",
    "print(\"rolling_data shape: {}\".format(rolling_data.shape))\n",
    "print(\"seq count: {}\".format(rolling_data.shape[0]))                                       # 所以一共有 seq_count 列数据，每一行的数据是123维 （包括y）\n",
    "print(\"seq length: {}\".format(SEQ_LENGTH))\n",
    "# print(\"batch size: {}\".format(BATCH_SIZE))\n",
    "\n",
    "test_seq_count = TEST_BATCH_COUNT * TEST_BATCH_SIZE\n",
    "\n",
    "\n",
    "# train = rolling_data[:-test_seq_count].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "# test  = rolling_data[-test_seq_count:].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "train = rolling_data[:-test_seq_count].reshape(-1, TRAIN_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                    # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "test  = rolling_data[-test_seq_count:].reshape(-1, TEST_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)      # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "TRAIN_BATCH_SIZE = train.shape[1]\n",
    "TRAIN_BATCH_COUNT = train.shape[0]\n",
    "TEST_BATCH_SIZE = test.shape[1]\n",
    "TEST_BATCH_COUNT = test.shape[0]\n",
    "\n",
    "train = torch.tensor(train)\n",
    "test  = torch.tensor(test)\n",
    "\n",
    "# train = rolling_data[:train_batch_count, :, :, :]\n",
    "# test  = rolling_data[train_batch_count:, :, :, :]\n",
    "\n",
    "train_x, train_y = train[:,:,:,Y_SEQ_LEN:], train[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "test_x,  test_y  = test[:,:,:, Y_SEQ_LEN:],  test[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "\n",
    "train_y = train_y.permute(0, 1, 3, 2)                                    # conver from [train_batch_count, batch_size, seq_length, y_seq_len]  to [train_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "test_y  =  test_y.permute(0, 1, 3, 2)                                    # conver from [test_batch_count, batch_size, seq_length, y_seq_len]  to  [test_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"test_x:  {}\".format(test_x.shape))\n",
    "print(\"test_y:  {}\".format(test_y.shape))\n",
    "print(\"train_batch_count: {}\".format(train.shape[0]))\n",
    "print(\"test_batch_count:  {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3033e44d-4dfa-4a7f-8fa6-b96783b5ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LSTM 模型\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        # self.h0 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        # self.c0 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        \n",
    "        self.init_weights2()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "    def init_weights2(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "    \n",
    "    def init_weights3(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def forward(self, x, hidden, cell):\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        # layer 1\n",
    "        # x = self.linear_1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # lstm_out, (h_n, c_n) = self.lstm(x, (self.h0.detach(), self.c0.detach()))\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(x, (hidden, cell))\n",
    "        \n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        # lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out)\n",
    "        \n",
    "        return predictions, h_n, c_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847eb8d0-f5f3-4943-ad9e-b9f2a7ba5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练 LSTM 模型 ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "\n",
    "HIDDEN_SIZE = 768\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "model = LSTMModel(input_size=X_DIM, hidden_layer_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1).double().to(device)\n",
    "LR = 1e-4\n",
    "loss_func = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "533d9251-af68-4657-a16a-e406fb4a1f39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 200 epoch loss: 0.1479 with lr: 0.0001\n",
      "1 of 200 epoch loss: 0.1643 with lr: 0.0001\n",
      "2 of 200 epoch loss: 0.1167 with lr: 0.0001\n",
      "3 of 200 epoch loss: 0.0669 with lr: 0.0001\n",
      "4 of 200 epoch loss: 0.0698 with lr: 0.0001\n",
      "5 of 200 epoch loss: 0.0560 with lr: 0.0001\n",
      "6 of 200 epoch loss: 0.0540 with lr: 0.0001\n",
      "7 of 200 epoch loss: 0.0538 with lr: 0.0001\n",
      "8 of 200 epoch loss: 0.0499 with lr: 0.0001\n",
      "9 of 200 epoch loss: 0.0548 with lr: 0.0001\n",
      "10 of 200 epoch loss: 0.0534 with lr: 0.0001\n",
      "11 of 200 epoch loss: 0.0524 with lr: 0.0001\n",
      "12 of 200 epoch loss: 0.0503 with lr: 0.0001\n",
      "13 of 200 epoch loss: 0.0455 with lr: 0.0001\n",
      "14 of 200 epoch loss: 0.0509 with lr: 0.0001\n",
      "15 of 200 epoch loss: 0.0470 with lr: 0.0001\n",
      "16 of 200 epoch loss: 0.0488 with lr: 0.0001\n",
      "17 of 200 epoch loss: 0.0492 with lr: 0.0001\n",
      "18 of 200 epoch loss: 0.0474 with lr: 0.0001\n",
      "19 of 200 epoch loss: 0.0446 with lr: 0.0001\n",
      "20 of 200 epoch loss: 0.0458 with lr: 0.0001\n",
      "21 of 200 epoch loss: 0.0460 with lr: 0.0001\n",
      "22 of 200 epoch loss: 0.0466 with lr: 0.0001\n",
      "23 of 200 epoch loss: 0.0444 with lr: 0.0001\n",
      "24 of 200 epoch loss: 0.0453 with lr: 0.0001\n",
      "25 of 200 epoch loss: 0.0421 with lr: 0.0001\n",
      "26 of 200 epoch loss: 0.0446 with lr: 0.0001\n",
      "27 of 200 epoch loss: 0.0404 with lr: 0.0001\n",
      "28 of 200 epoch loss: 0.0430 with lr: 0.0001\n",
      "29 of 200 epoch loss: 0.0440 with lr: 0.0001\n",
      "30 of 200 epoch loss: 0.0416 with lr: 0.0001\n",
      "31 of 200 epoch loss: 0.0431 with lr: 0.0001\n",
      "32 of 200 epoch loss: 0.0422 with lr: 0.0001\n",
      "33 of 200 epoch loss: 0.0440 with lr: 0.0001\n",
      "34 of 200 epoch loss: 0.0438 with lr: 0.0001\n",
      "35 of 200 epoch loss: 0.0406 with lr: 0.0001\n",
      "36 of 200 epoch loss: 0.0418 with lr: 0.0001\n",
      "37 of 200 epoch loss: 0.0408 with lr: 0.0001\n",
      "38 of 200 epoch loss: 0.0383 with lr: 0.0001\n",
      "39 of 200 epoch loss: 0.0433 with lr: 0.0001\n",
      "40 of 200 epoch loss: 0.0395 with lr: 0.0001\n",
      "41 of 200 epoch loss: 0.0400 with lr: 0.0001\n",
      "42 of 200 epoch loss: 0.0390 with lr: 0.0001\n",
      "43 of 200 epoch loss: 0.0387 with lr: 0.0001\n",
      "44 of 200 epoch loss: 0.0396 with lr: 0.0001\n",
      "45 of 200 epoch loss: 0.0413 with lr: 0.0001\n",
      "46 of 200 epoch loss: 0.0391 with lr: 0.0001\n",
      "47 of 200 epoch loss: 0.0387 with lr: 0.0001\n",
      "48 of 200 epoch loss: 0.0410 with lr: 0.0001\n",
      "49 of 200 epoch loss: 0.0387 with lr: 0.0001\n",
      "50 of 200 epoch loss: 0.0394 with lr: 0.0001\n",
      "51 of 200 epoch loss: 0.0391 with lr: 0.0001\n",
      "52 of 200 epoch loss: 0.0376 with lr: 0.0001\n",
      "53 of 200 epoch loss: 0.0372 with lr: 0.0001\n",
      "54 of 200 epoch loss: 0.0398 with lr: 0.0001\n",
      "55 of 200 epoch loss: 0.0367 with lr: 0.0001\n",
      "56 of 200 epoch loss: 0.0369 with lr: 0.0001\n",
      "57 of 200 epoch loss: 0.0402 with lr: 0.0001\n",
      "58 of 200 epoch loss: 0.0372 with lr: 0.0001\n",
      "59 of 200 epoch loss: 0.0369 with lr: 0.0001\n",
      "60 of 200 epoch loss: 0.0364 with lr: 0.0001\n",
      "61 of 200 epoch loss: 0.0369 with lr: 0.0001\n",
      "62 of 200 epoch loss: 0.0376 with lr: 0.0001\n",
      "63 of 200 epoch loss: 0.0357 with lr: 0.0001\n",
      "64 of 200 epoch loss: 0.0371 with lr: 0.0001\n",
      "65 of 200 epoch loss: 0.0396 with lr: 0.0001\n",
      "66 of 200 epoch loss: 0.0348 with lr: 0.0001\n",
      "67 of 200 epoch loss: 0.0356 with lr: 0.0001\n",
      "68 of 200 epoch loss: 0.0320 with lr: 0.0001\n",
      "69 of 200 epoch loss: 0.0345 with lr: 0.0001\n",
      "70 of 200 epoch loss: 0.0344 with lr: 0.0001\n",
      "71 of 200 epoch loss: 0.0317 with lr: 0.0001\n",
      "72 of 200 epoch loss: 0.0362 with lr: 0.0001\n",
      "73 of 200 epoch loss: 0.0343 with lr: 0.0001\n",
      "74 of 200 epoch loss: 0.0332 with lr: 0.0001\n",
      "75 of 200 epoch loss: 0.0335 with lr: 0.0001\n",
      "76 of 200 epoch loss: 0.0358 with lr: 0.0001\n",
      "77 of 200 epoch loss: 0.0333 with lr: 0.0001\n",
      "78 of 200 epoch loss: 0.0373 with lr: 0.0001\n",
      "79 of 200 epoch loss: 0.0376 with lr: 0.0001\n",
      "80 of 200 epoch loss: 0.0340 with lr: 0.0001\n",
      "81 of 200 epoch loss: 0.0388 with lr: 0.0001\n",
      "82 of 200 epoch loss: 0.0376 with lr: 0.0001\n",
      "83 of 200 epoch loss: 0.0382 with lr: 0.0001\n",
      "84 of 200 epoch loss: 0.0343 with lr: 0.0001\n",
      "85 of 200 epoch loss: 0.0348 with lr: 0.0001\n",
      "86 of 200 epoch loss: 0.0342 with lr: 0.0001\n",
      "87 of 200 epoch loss: 0.0352 with lr: 0.0001\n",
      "88 of 200 epoch loss: 0.0337 with lr: 0.0001\n",
      "89 of 200 epoch loss: 0.0317 with lr: 0.0001\n",
      "90 of 200 epoch loss: 0.0320 with lr: 0.0001\n",
      "91 of 200 epoch loss: 0.0330 with lr: 0.0001\n",
      "92 of 200 epoch loss: 0.0316 with lr: 0.0001\n",
      "93 of 200 epoch loss: 0.0312 with lr: 0.0001\n",
      "94 of 200 epoch loss: 0.0334 with lr: 0.0001\n",
      "95 of 200 epoch loss: 0.0318 with lr: 0.0001\n",
      "96 of 200 epoch loss: 0.0298 with lr: 0.0001\n",
      "97 of 200 epoch loss: 0.0322 with lr: 0.0001\n",
      "98 of 200 epoch loss: 0.0312 with lr: 0.0001\n",
      "99 of 200 epoch loss: 0.0333 with lr: 0.0001\n",
      "100 of 200 epoch loss: 0.0297 with lr: 0.0001\n",
      "101 of 200 epoch loss: 0.0316 with lr: 0.0001\n",
      "102 of 200 epoch loss: 0.0327 with lr: 0.0001\n",
      "103 of 200 epoch loss: 0.0310 with lr: 0.0001\n",
      "104 of 200 epoch loss: 0.0302 with lr: 0.0001\n",
      "105 of 200 epoch loss: 0.0301 with lr: 0.0001\n",
      "106 of 200 epoch loss: 0.0299 with lr: 0.0001\n",
      "107 of 200 epoch loss: 0.0322 with lr: 0.0001\n",
      "108 of 200 epoch loss: 0.0326 with lr: 0.0001\n",
      "109 of 200 epoch loss: 0.0308 with lr: 0.0001\n",
      "110 of 200 epoch loss: 0.0272 with lr: 0.0001\n",
      "111 of 200 epoch loss: 0.0310 with lr: 0.0001\n",
      "112 of 200 epoch loss: 0.0311 with lr: 0.0001\n",
      "113 of 200 epoch loss: 0.0298 with lr: 0.0001\n",
      "114 of 200 epoch loss: 0.0310 with lr: 0.0001\n",
      "115 of 200 epoch loss: 0.0312 with lr: 0.0001\n",
      "116 of 200 epoch loss: 0.0302 with lr: 0.0001\n",
      "117 of 200 epoch loss: 0.0290 with lr: 0.0001\n",
      "118 of 200 epoch loss: 0.0285 with lr: 0.0001\n",
      "119 of 200 epoch loss: 0.0299 with lr: 0.0001\n",
      "120 of 200 epoch loss: 0.0300 with lr: 0.0001\n",
      "121 of 200 epoch loss: 0.0305 with lr: 0.0001\n",
      "122 of 200 epoch loss: 0.0293 with lr: 0.0001\n",
      "123 of 200 epoch loss: 0.0300 with lr: 0.0001\n",
      "124 of 200 epoch loss: 0.0287 with lr: 0.0001\n",
      "125 of 200 epoch loss: 0.0305 with lr: 0.0001\n",
      "126 of 200 epoch loss: 0.0306 with lr: 0.0001\n",
      "127 of 200 epoch loss: 0.0275 with lr: 0.0001\n",
      "128 of 200 epoch loss: 0.0281 with lr: 0.0001\n",
      "129 of 200 epoch loss: 0.0269 with lr: 0.0001\n",
      "130 of 200 epoch loss: 0.0259 with lr: 0.0001\n",
      "131 of 200 epoch loss: 0.0287 with lr: 0.0001\n",
      "132 of 200 epoch loss: 0.0280 with lr: 0.0001\n",
      "133 of 200 epoch loss: 0.0298 with lr: 0.0001\n",
      "134 of 200 epoch loss: 0.0277 with lr: 0.0001\n",
      "135 of 200 epoch loss: 0.0270 with lr: 0.0001\n",
      "136 of 200 epoch loss: 0.0288 with lr: 0.0001\n",
      "137 of 200 epoch loss: 0.0282 with lr: 0.0001\n",
      "138 of 200 epoch loss: 0.0284 with lr: 0.0001\n",
      "139 of 200 epoch loss: 0.0265 with lr: 0.0001\n",
      "140 of 200 epoch loss: 0.0286 with lr: 0.0001\n",
      "141 of 200 epoch loss: 0.0292 with lr: 0.0001\n",
      "142 of 200 epoch loss: 0.0272 with lr: 0.0001\n",
      "143 of 200 epoch loss: 0.0258 with lr: 0.0001\n",
      "144 of 200 epoch loss: 0.0265 with lr: 0.0001\n",
      "145 of 200 epoch loss: 0.0291 with lr: 0.0001\n",
      "146 of 200 epoch loss: 0.0284 with lr: 0.0001\n",
      "147 of 200 epoch loss: 0.0278 with lr: 0.0001\n",
      "148 of 200 epoch loss: 0.0276 with lr: 0.0001\n",
      "149 of 200 epoch loss: 0.0251 with lr: 0.0001\n",
      "150 of 200 epoch loss: 0.0257 with lr: 0.0001\n",
      "151 of 200 epoch loss: 0.0272 with lr: 0.0001\n",
      "152 of 200 epoch loss: 0.0244 with lr: 0.0001\n",
      "153 of 200 epoch loss: 0.0247 with lr: 0.0001\n",
      "154 of 200 epoch loss: 0.0265 with lr: 0.0001\n",
      "155 of 200 epoch loss: 0.0264 with lr: 0.0001\n",
      "156 of 200 epoch loss: 0.0257 with lr: 0.0001\n",
      "157 of 200 epoch loss: 0.0250 with lr: 0.0001\n",
      "158 of 200 epoch loss: 0.0256 with lr: 0.0001\n",
      "159 of 200 epoch loss: 0.0276 with lr: 0.0001\n",
      "160 of 200 epoch loss: 0.0274 with lr: 0.0001\n",
      "161 of 200 epoch loss: 0.0263 with lr: 0.0001\n",
      "162 of 200 epoch loss: 0.0248 with lr: 0.0001\n",
      "163 of 200 epoch loss: 0.0265 with lr: 0.0001\n",
      "164 of 200 epoch loss: 0.0250 with lr: 0.0001\n",
      "165 of 200 epoch loss: 0.0247 with lr: 0.0001\n",
      "166 of 200 epoch loss: 0.0252 with lr: 0.0001\n",
      "167 of 200 epoch loss: 0.0256 with lr: 0.0001\n",
      "168 of 200 epoch loss: 0.0240 with lr: 0.0001\n",
      "169 of 200 epoch loss: 0.0253 with lr: 0.0001\n",
      "170 of 200 epoch loss: 0.0225 with lr: 0.0001\n",
      "171 of 200 epoch loss: 0.0250 with lr: 0.0001\n",
      "172 of 200 epoch loss: 0.0246 with lr: 0.0001\n",
      "173 of 200 epoch loss: 0.0273 with lr: 0.0001\n",
      "174 of 200 epoch loss: 0.0255 with lr: 0.0001\n",
      "175 of 200 epoch loss: 0.0252 with lr: 0.0001\n",
      "176 of 200 epoch loss: 0.0241 with lr: 0.0001\n",
      "177 of 200 epoch loss: 0.0257 with lr: 0.0001\n",
      "178 of 200 epoch loss: 0.0250 with lr: 0.0001\n",
      "179 of 200 epoch loss: 0.0249 with lr: 0.0001\n",
      "180 of 200 epoch loss: 0.0247 with lr: 0.0001\n",
      "181 of 200 epoch loss: 0.0234 with lr: 0.0001\n",
      "182 of 200 epoch loss: 0.0270 with lr: 0.0001\n",
      "183 of 200 epoch loss: 0.0253 with lr: 0.0001\n",
      "184 of 200 epoch loss: 0.0247 with lr: 0.0001\n",
      "185 of 200 epoch loss: 0.0245 with lr: 0.0001\n",
      "186 of 200 epoch loss: 0.0234 with lr: 0.0001\n",
      "187 of 200 epoch loss: 0.0236 with lr: 0.0001\n",
      "188 of 200 epoch loss: 0.0247 with lr: 0.0001\n",
      "189 of 200 epoch loss: 0.0227 with lr: 0.0001\n",
      "190 of 200 epoch loss: 0.0219 with lr: 0.0001\n",
      "191 of 200 epoch loss: 0.0226 with lr: 0.0001\n",
      "192 of 200 epoch loss: 0.0228 with lr: 0.0001\n",
      "193 of 200 epoch loss: 0.0219 with lr: 0.0001\n",
      "194 of 200 epoch loss: 0.0230 with lr: 0.0001\n",
      "195 of 200 epoch loss: 0.0222 with lr: 0.0001\n",
      "196 of 200 epoch loss: 0.0227 with lr: 0.0001\n",
      "197 of 200 epoch loss: 0.0237 with lr: 0.0001\n",
      "198 of 200 epoch loss: 0.0221 with lr: 0.0001\n",
      "199 of 200 epoch loss: 0.0219 with lr: 0.0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练 LSTM 模型;  ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "model.train()\n",
    "epoches = 200\n",
    "epoch_loss = 0\n",
    "epoch_loss_list = []\n",
    "train_batch_count = train_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for step in range(train_batch_count):\n",
    "        pred, hn, cn = model(train_x[step], h0, c0)\n",
    "        # h0, c0 = hn.detach(), cn.detach()\n",
    "        loss = loss_func(pred[:,-1], train_y[step][:,-1])                # Compare the all sequences' last element in one batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.data.cpu()\n",
    "        \n",
    "    if epoch_loss.item() < 1e-4:\n",
    "        print('Epoch [{}/{}], Loss: {:.5f}'.format(epoch+1, epoches, loss.item()))\n",
    "        print(\"The loss value is reached\")\n",
    "        break\n",
    "\n",
    "    print(\"{} of {} epoch loss: {:.4f} with lr: {}\".format(epoch, epoches, epoch_loss.item(), optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    if (epoch+1) % 2000 ==0:\n",
    "        scheduler.step()\n",
    "    # print(\"learning rate: {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    # for p in optimizer.param_groups:\n",
    "    #     p['lr'] *= 0.99\n",
    "    \n",
    "plt.plot(epoch_loss_list)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eab98543-e67b-4112-918f-6731252e65f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model, 'e:\\\\Model_LSTM1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de5e146b-9f2a-4822-8d7e-c71ee74a6730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = torch.load('e:\\\\Model_LSTM1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "602f9272-9fd8-40a2-ae45-f92f793bbe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Loss average:0.000651\n",
      "Prediction: -0.03\n",
      "Actual:     0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用模型预测数据\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_batch_count = test_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TEST_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TEST_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "\n",
    "actual_line=[]\n",
    "pred_line=[]\n",
    "\n",
    "for step in range(test_batch_count):\n",
    "    pred, hn, cn = model(test_x[step], h0, c0)\n",
    "    \n",
    "    h0, c0 = hn.detach(), cn.detach()\n",
    "\n",
    "    loss = loss_func(pred[:,-1], test_y[step][:,-1])                # Compare the all sequences' last element in one batch\n",
    "    \n",
    "    test_loss += loss.cpu()\n",
    "    \n",
    "    actual_line.append(test_y[step][-1,-1].item())\n",
    "    pred_line.append(pred[-1,-1].item())\n",
    "        \n",
    "print(\"Prediction Loss average:{:.6f}\".format(test_loss.data/(step+1)))\n",
    "print(\"Prediction: {:.2f}\".format(float(pred[-1,-1].data)))\n",
    "print(\"Actual:     {:.2f}\".format(float(test_y[step][-1,-1].data)))\n",
    "\n",
    "# actual_line = test_y[step][-1].cpu().detach().flatten().numpy()        # Only plot the last sequence of test batch\n",
    "# pred_line   = pred[-1].cpu().detach().flatten().numpy()                # Only plot the last sequence of test batch\n",
    "plt.plot(actual_line, 'r--')\n",
    "plt.plot(pred_line, 'b-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3c66f-e2ca-4818-9856-1c396c9319c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
