{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6e9707-a755-443b-8483-00b9df2ea38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 单层 LSTM 的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301a0bfe-88e2-4398-9334-cc77d8bb8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0c3f73-0613-4605-9691-ba3dfbbfbf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1027)\n",
    "torch.manual_seed(1027)\n",
    "torch.cuda.manual_seed(1027)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe160cab-111b-4904-abb0-8204a8a10669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 GPU 优先\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv(\"601229.csv\", index_col=0)\n",
    "dataset = dataset.drop(['date'], axis=1)\n",
    "dataset = dataset.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de255091-c7b4-4495-a035-b80b06317681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_data shape: (601, 60, 135)\n",
      "seq count: 601\n",
      "seq length: 60\n",
      "train_x: torch.Size([6, 100, 60, 134])\n",
      "train_y: torch.Size([6, 100, 1, 1])\n",
      "test_x:  torch.Size([1, 1, 60, 134])\n",
      "test_y:  torch.Size([1, 1, 1, 1])\n",
      "train_batch_count: 6\n",
      "test_batch_count:  1\n"
     ]
    }
   ],
   "source": [
    "# 将数据按照BATCH_SIZE的窗口进行滑动，每个窗口数据做一组\n",
    "# # 数据转成sequence的格式，这里定义每个seq的长度\n",
    "SEQ_LENGTH = 60\n",
    "TRAIN_BATCH_SIZE = 100                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_SIZE = 1                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_COUNT = 1\n",
    "Y_SEQ_LEN = 1                                                         # 要用2个y来表示预测的第一天和预测的第二天，对应 \"future\" 和 \"future2\",每个y都是1-D的，y的seq_len是2\n",
    "Y_DIM = 1\n",
    "X_DIM = dataset.shape[1]-Y_SEQ_LEN                                    # 表示输入的sequence里每个element有122维度，也是encoder的input_dim\n",
    "\n",
    "# 把数据切换成 BATCH_SIZE 的一个个batch\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                   # 数据一共是 seq_count x seq_len x (x_in_dim+Y_SEQ_LEN) \n",
    "\n",
    "print(\"rolling_data shape: {}\".format(rolling_data.shape))\n",
    "print(\"seq count: {}\".format(rolling_data.shape[0]))                                       # 所以一共有 seq_count 列数据，每一行的数据是123维 （包括y）\n",
    "print(\"seq length: {}\".format(SEQ_LENGTH))\n",
    "# print(\"batch size: {}\".format(BATCH_SIZE))\n",
    "\n",
    "test_seq_count = TEST_BATCH_COUNT * TEST_BATCH_SIZE\n",
    "\n",
    "\n",
    "# train = rolling_data[:-test_seq_count].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "# test  = rolling_data[-test_seq_count:].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "train = rolling_data[:-test_seq_count].reshape(-1, TRAIN_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                    # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "test  = rolling_data[-test_seq_count:].reshape(-1, TEST_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)      # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "TRAIN_BATCH_SIZE = train.shape[1]\n",
    "TRAIN_BATCH_COUNT = train.shape[0]\n",
    "TEST_BATCH_SIZE = test.shape[1]\n",
    "TEST_BATCH_COUNT = test.shape[0]\n",
    "\n",
    "train = torch.tensor(train)\n",
    "test  = torch.tensor(test)\n",
    "\n",
    "# train = rolling_data[:train_batch_count, :, :, :]\n",
    "# test  = rolling_data[train_batch_count:, :, :, :]\n",
    "\n",
    "train_x, train_y = train[:,:,:,Y_SEQ_LEN:], train[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "test_x,  test_y  = test[:,:,:, Y_SEQ_LEN:],  test[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "\n",
    "train_y = train_y.permute(0, 1, 3, 2)                                    # conver from [train_batch_count, batch_size, seq_length, y_seq_len]  to [train_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "test_y  =  test_y.permute(0, 1, 3, 2)                                    # conver from [test_batch_count, batch_size, seq_length, y_seq_len]  to  [test_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"test_x:  {}\".format(test_x.shape))\n",
    "print(\"test_y:  {}\".format(test_y.shape))\n",
    "print(\"train_batch_count: {}\".format(train.shape[0]))\n",
    "print(\"test_batch_count:  {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3033e44d-4dfa-4a7f-8fa6-b96783b5ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 LSTM 模型\n",
    "\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_size, num_layers, output_size, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(input_size, hidden_layer_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size, num_layers=num_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        # self.h0 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        # self.c0 = torch.zeros(NUM_LAYERS, BATCH_SIZE, hidden_layer_size).double().to(device)\n",
    "        \n",
    "        self.init_weights2()\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "    def init_weights2(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)    \n",
    "    \n",
    "    def init_weights3(self):\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "                \n",
    "    def forward(self, x, hidden, cell):\n",
    "        batchsize = x.shape[0]\n",
    "\n",
    "        # layer 1\n",
    "        # x = self.linear_1(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # lstm_out, (h_n, c_n) = self.lstm(x, (self.h0.detach(), self.c0.detach()))\n",
    "        \n",
    "        lstm_out, (h_n, c_n) = self.lstm(x, (hidden, cell))\n",
    "        \n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "\n",
    "        # lstm_out = self.dropout(lstm_out)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out)\n",
    "        \n",
    "        return predictions, h_n, c_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847eb8d0-f5f3-4943-ad9e-b9f2a7ba5c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练 LSTM 模型 ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "\n",
    "HIDDEN_SIZE = 768\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "model = LSTMModel(input_size=X_DIM, hidden_layer_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, output_size=1).double().to(device)\n",
    "LR = 1e-4\n",
    "loss_func = nn.MSELoss(reduction=\"mean\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-8)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "533d9251-af68-4657-a16a-e406fb4a1f39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 200 epoch loss: 0.2919 with lr: 0.0001\n",
      "1 of 200 epoch loss: 0.2090 with lr: 0.0001\n",
      "2 of 200 epoch loss: 0.1356 with lr: 0.0001\n",
      "3 of 200 epoch loss: 0.0848 with lr: 0.0001\n",
      "4 of 200 epoch loss: 0.0747 with lr: 0.0001\n",
      "5 of 200 epoch loss: 0.0727 with lr: 0.0001\n",
      "6 of 200 epoch loss: 0.0654 with lr: 0.0001\n",
      "7 of 200 epoch loss: 0.0593 with lr: 0.0001\n",
      "8 of 200 epoch loss: 0.0556 with lr: 0.0001\n",
      "9 of 200 epoch loss: 0.0560 with lr: 0.0001\n",
      "10 of 200 epoch loss: 0.0566 with lr: 0.0001\n",
      "11 of 200 epoch loss: 0.0545 with lr: 0.0001\n",
      "12 of 200 epoch loss: 0.0525 with lr: 0.0001\n",
      "13 of 200 epoch loss: 0.0520 with lr: 0.0001\n",
      "14 of 200 epoch loss: 0.0493 with lr: 0.0001\n",
      "15 of 200 epoch loss: 0.0542 with lr: 0.0001\n",
      "16 of 200 epoch loss: 0.0508 with lr: 0.0001\n",
      "17 of 200 epoch loss: 0.0534 with lr: 0.0001\n",
      "18 of 200 epoch loss: 0.0535 with lr: 0.0001\n",
      "19 of 200 epoch loss: 0.0523 with lr: 0.0001\n",
      "20 of 200 epoch loss: 0.0496 with lr: 0.0001\n",
      "21 of 200 epoch loss: 0.0519 with lr: 0.0001\n",
      "22 of 200 epoch loss: 0.0514 with lr: 0.0001\n",
      "23 of 200 epoch loss: 0.0524 with lr: 0.0001\n",
      "24 of 200 epoch loss: 0.0503 with lr: 0.0001\n",
      "25 of 200 epoch loss: 0.0523 with lr: 0.0001\n",
      "26 of 200 epoch loss: 0.0505 with lr: 0.0001\n",
      "27 of 200 epoch loss: 0.0486 with lr: 0.0001\n",
      "28 of 200 epoch loss: 0.0488 with lr: 0.0001\n",
      "29 of 200 epoch loss: 0.0474 with lr: 0.0001\n",
      "30 of 200 epoch loss: 0.0506 with lr: 0.0001\n",
      "31 of 200 epoch loss: 0.0465 with lr: 0.0001\n",
      "32 of 200 epoch loss: 0.0481 with lr: 0.0001\n",
      "33 of 200 epoch loss: 0.0491 with lr: 0.0001\n",
      "34 of 200 epoch loss: 0.0469 with lr: 0.0001\n",
      "35 of 200 epoch loss: 0.0460 with lr: 0.0001\n",
      "36 of 200 epoch loss: 0.0451 with lr: 0.0001\n",
      "37 of 200 epoch loss: 0.0459 with lr: 0.0001\n",
      "38 of 200 epoch loss: 0.0470 with lr: 0.0001\n",
      "39 of 200 epoch loss: 0.0483 with lr: 0.0001\n",
      "40 of 200 epoch loss: 0.0461 with lr: 0.0001\n",
      "41 of 200 epoch loss: 0.0461 with lr: 0.0001\n",
      "42 of 200 epoch loss: 0.0444 with lr: 0.0001\n",
      "43 of 200 epoch loss: 0.0466 with lr: 0.0001\n",
      "44 of 200 epoch loss: 0.0459 with lr: 0.0001\n",
      "45 of 200 epoch loss: 0.0458 with lr: 0.0001\n",
      "46 of 200 epoch loss: 0.0446 with lr: 0.0001\n",
      "47 of 200 epoch loss: 0.0456 with lr: 0.0001\n",
      "48 of 200 epoch loss: 0.0440 with lr: 0.0001\n",
      "49 of 200 epoch loss: 0.0472 with lr: 0.0001\n",
      "50 of 200 epoch loss: 0.0456 with lr: 0.0001\n",
      "51 of 200 epoch loss: 0.0457 with lr: 0.0001\n",
      "52 of 200 epoch loss: 0.0437 with lr: 0.0001\n",
      "53 of 200 epoch loss: 0.0433 with lr: 0.0001\n",
      "54 of 200 epoch loss: 0.0441 with lr: 0.0001\n",
      "55 of 200 epoch loss: 0.0441 with lr: 0.0001\n",
      "56 of 200 epoch loss: 0.0405 with lr: 0.0001\n",
      "57 of 200 epoch loss: 0.0406 with lr: 0.0001\n",
      "58 of 200 epoch loss: 0.0439 with lr: 0.0001\n",
      "59 of 200 epoch loss: 0.0428 with lr: 0.0001\n",
      "60 of 200 epoch loss: 0.0462 with lr: 0.0001\n",
      "61 of 200 epoch loss: 0.0429 with lr: 0.0001\n",
      "62 of 200 epoch loss: 0.0422 with lr: 0.0001\n",
      "63 of 200 epoch loss: 0.0410 with lr: 0.0001\n",
      "64 of 200 epoch loss: 0.0432 with lr: 0.0001\n",
      "65 of 200 epoch loss: 0.0439 with lr: 0.0001\n",
      "66 of 200 epoch loss: 0.0421 with lr: 0.0001\n",
      "67 of 200 epoch loss: 0.0435 with lr: 0.0001\n",
      "68 of 200 epoch loss: 0.0449 with lr: 0.0001\n",
      "69 of 200 epoch loss: 0.0446 with lr: 0.0001\n",
      "70 of 200 epoch loss: 0.0471 with lr: 0.0001\n",
      "71 of 200 epoch loss: 0.0443 with lr: 0.0001\n",
      "72 of 200 epoch loss: 0.0434 with lr: 0.0001\n",
      "73 of 200 epoch loss: 0.0419 with lr: 0.0001\n",
      "74 of 200 epoch loss: 0.0409 with lr: 0.0001\n",
      "75 of 200 epoch loss: 0.0411 with lr: 0.0001\n",
      "76 of 200 epoch loss: 0.0408 with lr: 0.0001\n",
      "77 of 200 epoch loss: 0.0396 with lr: 0.0001\n",
      "78 of 200 epoch loss: 0.0399 with lr: 0.0001\n",
      "79 of 200 epoch loss: 0.0420 with lr: 0.0001\n",
      "80 of 200 epoch loss: 0.0398 with lr: 0.0001\n",
      "81 of 200 epoch loss: 0.0406 with lr: 0.0001\n",
      "82 of 200 epoch loss: 0.0449 with lr: 0.0001\n",
      "83 of 200 epoch loss: 0.0423 with lr: 0.0001\n",
      "84 of 200 epoch loss: 0.0417 with lr: 0.0001\n",
      "85 of 200 epoch loss: 0.0387 with lr: 0.0001\n",
      "86 of 200 epoch loss: 0.0403 with lr: 0.0001\n",
      "87 of 200 epoch loss: 0.0368 with lr: 0.0001\n",
      "88 of 200 epoch loss: 0.0395 with lr: 0.0001\n",
      "89 of 200 epoch loss: 0.0391 with lr: 0.0001\n",
      "90 of 200 epoch loss: 0.0377 with lr: 0.0001\n",
      "91 of 200 epoch loss: 0.0408 with lr: 0.0001\n",
      "92 of 200 epoch loss: 0.0384 with lr: 0.0001\n",
      "93 of 200 epoch loss: 0.0402 with lr: 0.0001\n",
      "94 of 200 epoch loss: 0.0369 with lr: 0.0001\n",
      "95 of 200 epoch loss: 0.0374 with lr: 0.0001\n",
      "96 of 200 epoch loss: 0.0396 with lr: 0.0001\n",
      "97 of 200 epoch loss: 0.0383 with lr: 0.0001\n",
      "98 of 200 epoch loss: 0.0378 with lr: 0.0001\n",
      "99 of 200 epoch loss: 0.0371 with lr: 0.0001\n",
      "100 of 200 epoch loss: 0.0381 with lr: 0.0001\n",
      "101 of 200 epoch loss: 0.0366 with lr: 0.0001\n",
      "102 of 200 epoch loss: 0.0383 with lr: 0.0001\n",
      "103 of 200 epoch loss: 0.0351 with lr: 0.0001\n",
      "104 of 200 epoch loss: 0.0369 with lr: 0.0001\n",
      "105 of 200 epoch loss: 0.0356 with lr: 0.0001\n",
      "106 of 200 epoch loss: 0.0361 with lr: 0.0001\n",
      "107 of 200 epoch loss: 0.0378 with lr: 0.0001\n",
      "108 of 200 epoch loss: 0.0364 with lr: 0.0001\n",
      "109 of 200 epoch loss: 0.0375 with lr: 0.0001\n",
      "110 of 200 epoch loss: 0.0360 with lr: 0.0001\n",
      "111 of 200 epoch loss: 0.0377 with lr: 0.0001\n",
      "112 of 200 epoch loss: 0.0371 with lr: 0.0001\n",
      "113 of 200 epoch loss: 0.0362 with lr: 0.0001\n",
      "114 of 200 epoch loss: 0.0351 with lr: 0.0001\n",
      "115 of 200 epoch loss: 0.0363 with lr: 0.0001\n",
      "116 of 200 epoch loss: 0.0354 with lr: 0.0001\n",
      "117 of 200 epoch loss: 0.0351 with lr: 0.0001\n",
      "118 of 200 epoch loss: 0.0336 with lr: 0.0001\n",
      "119 of 200 epoch loss: 0.0363 with lr: 0.0001\n",
      "120 of 200 epoch loss: 0.0358 with lr: 0.0001\n",
      "121 of 200 epoch loss: 0.0372 with lr: 0.0001\n",
      "122 of 200 epoch loss: 0.0364 with lr: 0.0001\n",
      "123 of 200 epoch loss: 0.0343 with lr: 0.0001\n",
      "124 of 200 epoch loss: 0.0385 with lr: 0.0001\n",
      "125 of 200 epoch loss: 0.0360 with lr: 0.0001\n",
      "126 of 200 epoch loss: 0.0351 with lr: 0.0001\n",
      "127 of 200 epoch loss: 0.0352 with lr: 0.0001\n",
      "128 of 200 epoch loss: 0.0370 with lr: 0.0001\n",
      "129 of 200 epoch loss: 0.0391 with lr: 0.0001\n",
      "130 of 200 epoch loss: 0.0336 with lr: 0.0001\n",
      "131 of 200 epoch loss: 0.0347 with lr: 0.0001\n",
      "132 of 200 epoch loss: 0.0340 with lr: 0.0001\n",
      "133 of 200 epoch loss: 0.0322 with lr: 0.0001\n",
      "134 of 200 epoch loss: 0.0335 with lr: 0.0001\n",
      "135 of 200 epoch loss: 0.0347 with lr: 0.0001\n",
      "136 of 200 epoch loss: 0.0351 with lr: 0.0001\n",
      "137 of 200 epoch loss: 0.0346 with lr: 0.0001\n",
      "138 of 200 epoch loss: 0.0354 with lr: 0.0001\n",
      "139 of 200 epoch loss: 0.0340 with lr: 0.0001\n",
      "140 of 200 epoch loss: 0.0331 with lr: 0.0001\n",
      "141 of 200 epoch loss: 0.0353 with lr: 0.0001\n",
      "142 of 200 epoch loss: 0.0334 with lr: 0.0001\n",
      "143 of 200 epoch loss: 0.0347 with lr: 0.0001\n",
      "144 of 200 epoch loss: 0.0339 with lr: 0.0001\n",
      "145 of 200 epoch loss: 0.0322 with lr: 0.0001\n",
      "146 of 200 epoch loss: 0.0321 with lr: 0.0001\n",
      "147 of 200 epoch loss: 0.0305 with lr: 0.0001\n",
      "148 of 200 epoch loss: 0.0314 with lr: 0.0001\n",
      "149 of 200 epoch loss: 0.0317 with lr: 0.0001\n",
      "150 of 200 epoch loss: 0.0336 with lr: 0.0001\n",
      "151 of 200 epoch loss: 0.0310 with lr: 0.0001\n",
      "152 of 200 epoch loss: 0.0329 with lr: 0.0001\n",
      "153 of 200 epoch loss: 0.0321 with lr: 0.0001\n",
      "154 of 200 epoch loss: 0.0307 with lr: 0.0001\n",
      "155 of 200 epoch loss: 0.0300 with lr: 0.0001\n",
      "156 of 200 epoch loss: 0.0310 with lr: 0.0001\n",
      "157 of 200 epoch loss: 0.0320 with lr: 0.0001\n",
      "158 of 200 epoch loss: 0.0314 with lr: 0.0001\n",
      "159 of 200 epoch loss: 0.0330 with lr: 0.0001\n",
      "160 of 200 epoch loss: 0.0316 with lr: 0.0001\n",
      "161 of 200 epoch loss: 0.0340 with lr: 0.0001\n",
      "162 of 200 epoch loss: 0.0363 with lr: 0.0001\n",
      "163 of 200 epoch loss: 0.0322 with lr: 0.0001\n",
      "164 of 200 epoch loss: 0.0292 with lr: 0.0001\n",
      "165 of 200 epoch loss: 0.0298 with lr: 0.0001\n",
      "166 of 200 epoch loss: 0.0318 with lr: 0.0001\n",
      "167 of 200 epoch loss: 0.0332 with lr: 0.0001\n",
      "168 of 200 epoch loss: 0.0341 with lr: 0.0001\n",
      "169 of 200 epoch loss: 0.0309 with lr: 0.0001\n",
      "170 of 200 epoch loss: 0.0301 with lr: 0.0001\n",
      "171 of 200 epoch loss: 0.0319 with lr: 0.0001\n",
      "172 of 200 epoch loss: 0.0332 with lr: 0.0001\n",
      "173 of 200 epoch loss: 0.0315 with lr: 0.0001\n",
      "174 of 200 epoch loss: 0.0311 with lr: 0.0001\n",
      "175 of 200 epoch loss: 0.0301 with lr: 0.0001\n",
      "176 of 200 epoch loss: 0.0311 with lr: 0.0001\n",
      "177 of 200 epoch loss: 0.0305 with lr: 0.0001\n",
      "178 of 200 epoch loss: 0.0323 with lr: 0.0001\n",
      "179 of 200 epoch loss: 0.0299 with lr: 0.0001\n",
      "180 of 200 epoch loss: 0.0307 with lr: 0.0001\n",
      "181 of 200 epoch loss: 0.0288 with lr: 0.0001\n",
      "182 of 200 epoch loss: 0.0294 with lr: 0.0001\n",
      "183 of 200 epoch loss: 0.0293 with lr: 0.0001\n",
      "184 of 200 epoch loss: 0.0293 with lr: 0.0001\n",
      "185 of 200 epoch loss: 0.0297 with lr: 0.0001\n",
      "186 of 200 epoch loss: 0.0276 with lr: 0.0001\n",
      "187 of 200 epoch loss: 0.0300 with lr: 0.0001\n",
      "188 of 200 epoch loss: 0.0292 with lr: 0.0001\n",
      "189 of 200 epoch loss: 0.0298 with lr: 0.0001\n",
      "190 of 200 epoch loss: 0.0288 with lr: 0.0001\n",
      "191 of 200 epoch loss: 0.0284 with lr: 0.0001\n",
      "192 of 200 epoch loss: 0.0298 with lr: 0.0001\n",
      "193 of 200 epoch loss: 0.0310 with lr: 0.0001\n",
      "194 of 200 epoch loss: 0.0298 with lr: 0.0001\n",
      "195 of 200 epoch loss: 0.0268 with lr: 0.0001\n",
      "196 of 200 epoch loss: 0.0266 with lr: 0.0001\n",
      "197 of 200 epoch loss: 0.0268 with lr: 0.0001\n",
      "198 of 200 epoch loss: 0.0267 with lr: 0.0001\n",
      "199 of 200 epoch loss: 0.0283 with lr: 0.0001\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 训练 LSTM 模型;  ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "model.train()\n",
    "epoches = 200\n",
    "epoch_loss = 0\n",
    "epoch_loss_list = []\n",
    "train_batch_count = train_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for step in range(train_batch_count):\n",
    "        pred, hn, cn = model(train_x[step], h0, c0)\n",
    "        # h0, c0 = hn.detach(), cn.detach()\n",
    "        loss = loss_func(pred[:,-1], train_y[step][:,-1])                # Compare the all sequences' last element in one batch\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.data.cpu()\n",
    "        \n",
    "    if epoch_loss.item() < 1e-4:\n",
    "        print('Epoch [{}/{}], Loss: {:.5f}'.format(epoch+1, epoches, loss.item()))\n",
    "        print(\"The loss value is reached\")\n",
    "        break\n",
    "\n",
    "    print(\"{} of {} epoch loss: {:.4f} with lr: {}\".format(epoch, epoches, epoch_loss.item(), optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    epoch_loss_list.append(epoch_loss)\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    if (epoch+1) % 2000 ==0:\n",
    "        scheduler.step()\n",
    "    # print(\"learning rate: {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    # for p in optimizer.param_groups:\n",
    "    #     p['lr'] *= 0.99\n",
    "    \n",
    "plt.plot(epoch_loss_list)\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab98543-e67b-4112-918f-6731252e65f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model, 'e:\\\\Model_LSTM1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de5e146b-9f2a-4822-8d7e-c71ee74a6730",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "model = torch.load('e:\\\\Model_LSTM1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "602f9272-9fd8-40a2-ae45-f92f793bbe5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Loss average:0.000403\n",
      "Prediction: -0.02\n",
      "Actual:     0.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 用模型预测数据\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_batch_count = test_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TEST_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TEST_BATCH_SIZE, HIDDEN_SIZE).double().to(device)\n",
    "\n",
    "actual_line=[]\n",
    "pred_line=[]\n",
    "\n",
    "for step in range(test_batch_count):\n",
    "    pred, hn, cn = model(test_x[step], h0, c0)\n",
    "    \n",
    "    h0, c0 = hn.detach(), cn.detach()\n",
    "\n",
    "    loss = loss_func(pred[:,-1], test_y[step][:,-1])                # Compare the all sequences' last element in one batch\n",
    "    \n",
    "    test_loss += loss.cpu()\n",
    "    \n",
    "    actual_line.append(test_y[step][-1,-1].item())\n",
    "    pred_line.append(pred[-1,-1].item())\n",
    "        \n",
    "print(\"Prediction Loss average:{:.6f}\".format(test_loss.data/(step+1)))\n",
    "print(\"Prediction: {:.2f}\".format(float(pred[-1,-1].data)))\n",
    "print(\"Actual:     {:.2f}\".format(float(test_y[step][-1,-1].data)))\n",
    "\n",
    "# actual_line = test_y[step][-1].cpu().detach().flatten().numpy()        # Only plot the last sequence of test batch\n",
    "# pred_line   = pred[-1].cpu().detach().flatten().numpy()                # Only plot the last sequence of test batch\n",
    "plt.plot(actual_line, 'r--')\n",
    "plt.plot(pred_line, 'b-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb3c66f-e2ca-4818-9856-1c396c9319c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
