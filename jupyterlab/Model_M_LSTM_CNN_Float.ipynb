{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6e9707-a755-443b-8483-00b9df2ea38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN + LSTM + Multi-Head-Attention 的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "301a0bfe-88e2-4398-9334-cc77d8bb8563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0c3f73-0613-4605-9691-ba3dfbbfbf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "torch.manual_seed(3)\n",
    "torch.cuda.manual_seed(3)\n",
    "\n",
    "# np.random.seed(1027)\n",
    "# torch.manual_seed(1027)\n",
    "# torch.cuda.manual_seed(1027)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe160cab-111b-4904-abb0-8204a8a10669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1267, 136)\n",
      "(1267, 137)\n",
      "Index(['future', 'close', 'hl_pct', 'co_pct', 'vm5_pct', 'close-sma5',\n",
      "       'close-sma10', 'close-sma30', 'close-sma60', 'close-sma90',\n",
      "       ...\n",
      "       'max5-max60', 'max10-max30', 'max10-max60', 'max30-max60', 'mon', 'tue',\n",
      "       'wed', 'thr', 'fri', 'dummy'],\n",
      "      dtype='object', length=137)\n"
     ]
    }
   ],
   "source": [
    "# 设置 GPU 优先\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 加载数据\n",
    "dataset = pd.read_csv(\"601229_price_qfq_137dims.csv\", index_col=0)\n",
    "# dataset = pd.read_csv(\"601229_price_qfq_137dims_part.csv\", index_col=0)\n",
    "# dataset = dataset.drop(['date'], axis=1)\n",
    "dataset = dataset.fillna(0)\n",
    "print(dataset.shape)\n",
    "if dataset.shape[0] %2 == 1:                                                  # 因为 position_encoding需要偶数的dim，才能对称\n",
    "    dataset['dummy'] = 0\n",
    "print(dataset.shape)\n",
    "print(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e812258d-0a75-4bff-b1eb-383f1f9f96be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rolling_data shape: (1243, 25, 137)\n",
      "seq count: 1243\n",
      "seq length: 25\n",
      "TRAIN_BATCH_COUNT : 139\n",
      "VALID_BATCH_COUNT : 16\n",
      "TEST_BATCH_COUNT  : 1\n",
      "train_x: torch.Size([139, 8, 25, 136])\n",
      "train_y: torch.Size([139, 8, 1, 1])\n",
      "valid_x: torch.Size([16, 8, 25, 136])\n",
      "valid_y: torch.Size([16, 8, 1, 1])\n",
      "test_x:  torch.Size([1, 3, 25, 136])\n",
      "test_y:  torch.Size([1, 3, 1, 1])\n",
      "train_batch_count: 139\n",
      "valid_batch_count: 16\n",
      "test_batch_count:  1\n"
     ]
    }
   ],
   "source": [
    "# 将数据按照BATCH_SIZE的窗口进行滑动，每个窗口数据做一组\n",
    "# # 数据转成sequence的格式，这里定义每个seq的长度\n",
    "TRAIN_VALIDATION_RATIO = 0.9\n",
    "TRAIN_BATCH_SIZE = 8                                                        # 注意：BATCH_SIZE是要能够整除(total_seq_count-1)的\n",
    "TEST_BATCH_SIZE = 1\n",
    "SEQ_LENGTH = 25\n",
    "Y_SEQ_LEN = 1                                                         # 要用2个y来表示预测的第一天和预测的第二天，对应 \"future\" 和 \"future2\",每个y都是1-D的，y的seq_len是2\n",
    "Y_DIM = 1\n",
    "X_DIM = dataset.shape[1]-Y_SEQ_LEN                                    # 表示输入的sequence里每个element有122维度，也是encoder的input_dim\n",
    "\n",
    "# 把数据切换成 BATCH_SIZE 的一个个batch\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                   # 数据一共是 seq_count x seq_len x (x_in_dim+Y_SEQ_LEN) \n",
    "\n",
    "# 打乱train数据\n",
    "# np.random.shuffle(rolling_data)\n",
    "\n",
    "print(\"rolling_data shape: {}\".format(rolling_data.shape))\n",
    "print(\"seq count: {}\".format(rolling_data.shape[0]))                                       # 所以一共有 seq_count 列数据，每一行的数据是123维 （包括y）\n",
    "print(\"seq length: {}\".format(SEQ_LENGTH))\n",
    "\n",
    "# TEST_BATCH_COUNT  = (rolling_data.shape[0])%TRAIN_BATCH_SIZE\n",
    "TEST_BATCH_SIZE  = (rolling_data.shape[0])%TRAIN_BATCH_SIZE\n",
    "if TEST_BATCH_SIZE == 0:                                                                   # 如果 rolling_data 刚好被整除，那就专门留一整块给test，全部算一个batch\n",
    "    TEST_BATCH_SIZE = TRAIN_BATCH_SIZE\n",
    "TEST_BATCH_COUNT = 1\n",
    "TRAIN_BATCH_COUNT = int(((rolling_data.shape[0]-TEST_BATCH_SIZE*TEST_BATCH_COUNT)//TRAIN_BATCH_SIZE) * TRAIN_VALIDATION_RATIO)\n",
    "VALID_BATCH_COUNT = int(((rolling_data.shape[0]-TEST_BATCH_SIZE*TEST_BATCH_COUNT)//TRAIN_BATCH_SIZE) - TRAIN_BATCH_COUNT)\n",
    "\n",
    "print(\"TRAIN_BATCH_COUNT : {}\".format(TRAIN_BATCH_COUNT))\n",
    "print(\"VALID_BATCH_COUNT : {}\".format(VALID_BATCH_COUNT))\n",
    "print(\"TEST_BATCH_COUNT  : {}\".format(TEST_BATCH_COUNT))\n",
    "\n",
    "# train = rolling_data[:-test_seq_count].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 tain_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "# test  = rolling_data[-test_seq_count:].reshape(-1, BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)           # 把数据转成 test_batch_count x BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "train = rolling_data[:TRAIN_BATCH_COUNT*TRAIN_BATCH_SIZE].reshape(TRAIN_BATCH_COUNT, TRAIN_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_DIM*Y_SEQ_LEN)                    # 把数据转成 tain_batch_count x TRAIN_BATCH_SIZE x seq_len x in_dim 格式\n",
    "valid = rolling_data[TRAIN_BATCH_COUNT*TRAIN_BATCH_SIZE:-TEST_BATCH_COUNT*TEST_BATCH_SIZE].reshape(VALID_BATCH_COUNT, TRAIN_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_DIM*Y_SEQ_LEN)     # 把数据转成 tain_batch_count x TRAIN_BATCH_SIZE x seq_len x in_dim 格式\n",
    "test  = rolling_data[-TEST_BATCH_COUNT*TEST_BATCH_SIZE:].reshape(TEST_BATCH_COUNT, TEST_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_DIM*Y_SEQ_LEN)                     # 把数据转成 test_batch_count x TEST_BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "TRAIN_BATCH_COUNT = train.shape[0]\n",
    "TRAIN_BATCH_SIZE = train.shape[1]\n",
    "VALID_BATCH_COUNT = valid.shape[0]\n",
    "VALID_BATCH_SIZE = valid.shape[1]\n",
    "TEST_BATCH_COUNT = test.shape[0]\n",
    "TEST_BATCH_SIZE = test.shape[1]\n",
    "\n",
    "train = torch.tensor(train)\n",
    "valid = torch.tensor(valid)\n",
    "test  = torch.tensor(test)\n",
    "\n",
    "\n",
    "train_x, train_y = train[:,:,:,Y_SEQ_LEN:], train[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "valid_x, valid_y = valid[:,:,:,Y_SEQ_LEN:], valid[:,:,-1:,0:Y_SEQ_LEN]           # [valid_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "test_x,  test_y  = test[:,:,:, Y_SEQ_LEN:],  test[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "\n",
    "train_y = train_y.permute(0, 1, 3, 2)                                    # conver from [train_batch_count, batch_size, seq_length, y_seq_len]  to [train_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "valid_y = valid_y.permute(0, 1, 3, 2)                                    # conver from [train_batch_count, batch_size, seq_length, y_seq_len]  to [train_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "test_y  =  test_y.permute(0, 1, 3, 2)                                    # conver from [test_batch_count, batch_size, seq_length, y_seq_len]  to  [test_batch_count, batch_size, y_seq_len, 1-dim]\n",
    "\n",
    "\n",
    "train_x = train_x.to(device)\n",
    "train_y = train_y.to(device)\n",
    "valid_x = valid_x.to(device)\n",
    "valid_y = valid_y.to(device)\n",
    "test_x = test_x.to(device)\n",
    "test_y = test_y.to(device)\n",
    "\n",
    "print(\"train_x: {}\".format(train_x.shape))\n",
    "print(\"train_y: {}\".format(train_y.shape))\n",
    "print(\"valid_x: {}\".format(valid_x.shape))\n",
    "print(\"valid_y: {}\".format(valid_y.shape))\n",
    "print(\"test_x:  {}\".format(test_x.shape))\n",
    "print(\"test_y:  {}\".format(test_y.shape))\n",
    "print(\"train_batch_count: {}\".format(train.shape[0]))\n",
    "print(\"valid_batch_count: {}\".format(valid.shape[0]))\n",
    "print(\"test_batch_count:  {}\".format(test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3699882f-47e3-4cd3-a9ca-9be52a8f89e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 PositionEncoding 模型\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)                                                                  # seq_len x input_dim\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)                                 # seq_len x 1\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))          # input_dim/2\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x: [seq_len, batch_size, d_model]\n",
    "        '''\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "# 定义 LSTM 模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim_size, num_layers, output_dim_size, seq_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_dim_size\n",
    "        self.max_seq_len = seq_len\n",
    "        self.num_layers = num_layers\n",
    "        self.input_dim_size = input_size\n",
    "        self.output_dim_size = output_dim_size\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.post=PositionalEncoding(d_model=self.input_dim_size, dropout=0.1, max_len=self.max_seq_len)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(self.input_dim_size, 512, kernel_size=3, padding='same')\n",
    "        self.conv2 = nn.Conv1d(self.input_dim_size, 512, kernel_size=5, padding='same')\n",
    "        self.conv3 = nn.Conv1d(self.input_dim_size, 512, kernel_size=7, padding='same')\n",
    "        self.conv4 = nn.Conv1d(self.input_dim_size, 512, kernel_size=9, padding='same')\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(self.hidden_size)\n",
    "\n",
    "        self.conv31 = nn.Conv1d(self.hidden_size, int(self.hidden_size/2), kernel_size=3, padding='same')\n",
    "        self.conv32 = nn.Conv1d(self.hidden_size, int(self.hidden_size/2), kernel_size=5, padding='same')\n",
    "        self.conv33 = nn.Conv1d(self.hidden_size, int(self.hidden_size/2), kernel_size=7, padding='same')\n",
    "        self.conv34 = nn.Conv1d(self.hidden_size, int(self.hidden_size/2), kernel_size=9, padding='same')\n",
    "        self.linear35 = nn.Linear(64, self.output_dim_size)    # 这个是给最后的多头注意力再乘 W0 的\n",
    "\n",
    "        self.num_attention_head = 256                                                                 # 64\n",
    "        self.attention_head_size = int(self.hidden_size/self.num_attention_head)                      # 每个头是32个维度\n",
    "        self.all_head_size = self.num_attention_head * self.attention_head_size                       # 所有的头的维度合集\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(self.hidden_size, elementwise_affine=False)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=self.input_dim_size,       hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True, dropout=dropout)\n",
    "        self.lstm2 = nn.LSTM(input_size=self.hidden_size,          hidden_size=self.hidden_size, num_layers=self.num_layers, batch_first=True, dropout=dropout)\n",
    "\n",
    "        # self.linear_1 = nn.Linear(self.input_dim_size, self.hidden_size)          # 这个是将输入的维度转换成 hidden_dim 的\n",
    "        self.linear_2 = nn.Linear(self.hidden_size, self.hidden_size)             # 这个是给最后的多头注意力再乘 W0 的\n",
    "        self.linear_3 = nn.Linear(2048, self.hidden_size)         # 这个是最后输出时将每个element的hidden_dim转成需要的out_dim\n",
    "        self.linear_4 = nn.Linear(self.hidden_size, 1)                            # 这个是最后输出时将整个seq的输出转成一个值\n",
    "\n",
    "        self.relu = nn.LeakyReLU()                                       # 用 relu 来增强模型非线性\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.query = nn.Linear(self.hidden_size, self.all_head_size)     # 输入768， 输出多头的维度总数。这里还是768.\n",
    "        self.key = nn.Linear(self.hidden_size, self.all_head_size)       # 输入768， 输出多头的维度总数。这里还是768.\n",
    "        self.value = nn.Linear(self.hidden_size, self.all_head_size)     # 输入768， 输出多头的维度总数。这里还是768.\n",
    "\n",
    "        self.init_weights3()\n",
    "\n",
    "    def init_weights1(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "    def init_weights2(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "\n",
    "    def init_weights3(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "    def init_weights4(self):\n",
    "        for name, param in self.lstm1.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.normal_(param, mean=0, std=1)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "        for name, param in self.lstm2.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.normal_(param, mean=0, std=1)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "\n",
    "    def attention_net(self, in_value, mask=None):\n",
    "        batch_size = in_value.shape[0]\n",
    "        seq_len = in_value.shape[1]\n",
    "        hidden_dim = in_value.shape[2]\n",
    "\n",
    "        # Q : [batch_size, seq_len, hidden_dim] ==> [batch_size, seq_len, num_head, head_size] ==> [batch_size, num_head, seq_len, head_size]\n",
    "        Q = self.query(in_value).reshape(batch_size, seq_len, self.num_attention_head, self.attention_head_size).permute(0, 2, 1, 3)      # 先将 hidden_dim 切成 num_head * head_size ，再将 num_head 和 seq_len互换\n",
    "        K = self.key(in_value).reshape(batch_size, seq_len, self.num_attention_head, self.attention_head_size).permute(0, 2, 1, 3)        # 先将 hidden_dim 切成 num_head * head_size ，再将 num_head 和 seq_len互换\n",
    "        V = self.value(in_value).reshape(batch_size, seq_len, self.num_attention_head, self.attention_head_size).permute(0, 2, 1, 3)      # 先将 hidden_dim 切成 num_head * head_size ，再将 num_head 和 seq_len互换\n",
    "\n",
    "        # d_k = Q.size(-1)                                                                            # d_k为query的维度。避免概率接近0\n",
    "\n",
    "        # attention_scores = torch.matmul(query, lstm_output.transpose(1, 2)) / math.sqrt(d_k)     #打分机制  [batch_size, seq_len, hid_dim] * [batch_size, hid_dim, seq_len] ==> scores:[batch_size, seq_len, seq_len], 每个值就是两个输入x元素的相似性\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-1, -2))                                    # [batch_size, num_head, seq_len, head_size] * [batch_size, num_head, head_size, seq_len] ==> [batch_size, num_head, seq_len, seq_len]\n",
    "\n",
    "        # attention_scores = attention_scores / math.sqrt(d_k)                                       # [batch_size, seq_len, seq_len]\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)                  # 多头机制下，hidden-dim被划分为 num_head个区域，所以现在要除的就是每个小区域的维度开方\n",
    "\n",
    "        # alpha = F.softmax(attention_scores, dim = -1)                                            #对最后一个维度归一化得分  [batch_size, seq_len, seq_len] 保证相似性在一行上归一了。\n",
    "        alpha = nn.Softmax(dim=-1)(attention_scores)                                               # 因为alpha是方阵，0维的seq_len就是真正的序列长度，1维的seq_len是对应每一个element和序列元素相关性。\n",
    "\n",
    "        # alpha = self.dropout(alpha)\n",
    "\n",
    "        attention = torch.matmul(alpha, V)                                            # [batch_size, num_head, seq_len, seq_len] * [batch_size, num_head, seq_len, head_size] = [batch_size, num_head, seq_len, head_size]\n",
    "\n",
    "        attention = attention.permute(0, 2, 1, 3).contiguous()                       # [batch_size, num_head, seq_len, head_size] ==> [batch_size, seq_len, num_head, head_size]\n",
    "        # new_attention_shape = attention.size()[:-2] + (self.all_head_size,)\n",
    "        # attention = attention.view(*new_attention_shape)\n",
    "        attention = attention.reshape(batch_size, seq_len, self.all_head_size)\n",
    "\n",
    "        attention = self.linear_2(attention)\n",
    "\n",
    "        return attention\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.float()\n",
    "        \n",
    "        # 下面这是 position_encoding 实现\n",
    "        x = x.permute(1, 0, 2)                                                                 # 转化为 seq_len * batch_size * hidden_dim\n",
    "        # 输入的维度： seq_len * batch * hidden_dim\n",
    "        x = self.post(x)\n",
    "        # 输出的维度： seq_len * batch * hidden_dim\n",
    "        x = x.permute(1, 0, 2)                                                                 # 转化为 batch_size * seq_len * hidden_dim\n",
    "\n",
    "        # 下面这是双 LSTM+Attention 实现\n",
    "        lstm_out, (h1_n, c1_n) = self.lstm1(x, (hidden, cell))\n",
    "        lstm_out = self.dropout(lstm_out)\n",
    "        lstm_out,  (h2_n, c2_n) = self.lstm2(lstm_out, (h1_n, c1_n))\n",
    "        # output = self.dropout(lstm_out)\n",
    "        output = self.attention_net(lstm_out)                                             # 和LSTM的不同就在于这一句   40 x 25 x 1024 [batch_size, seq_len, dim]\n",
    "        output = output.permute(0, 2, 1)                                              # 40 x 1024 x 25 [batch_size, dim, seq_len]\n",
    "        \n",
    "        # 下面这是 CNN-1D 的实现\n",
    "        cov_output01 = F.relu(self.conv31(output))                                         # 40 x 512 x 25 [batch_size, dim, seq_len]\n",
    "        cov_output01 = cov_output01.permute(0, 2, 1)                                            # 40 x 25 x 512 [batch_size, seq_len, dim]\n",
    "        # cov_output01 = F.max_pool1d(cov_output01, 1)                                           # 40 x 25 x 256 [batch_size, seq_len, dim]\n",
    "        # cov_output01  = output.permute(0, 2, 1) \n",
    "        \n",
    "        cov_output02 = F.relu(self.conv32(output))\n",
    "        cov_output02 = cov_output02.permute(0, 2, 1)\n",
    "        # cov_output02 = F.max_pool1d(cov_output02, 2)\n",
    "\n",
    "        cov_output03 = F.relu(self.conv33(output))\n",
    "        cov_output03 = cov_output03.permute(0, 2, 1)\n",
    "        # cov_output03 = F.max_pool1d(cov_output03, 3)\n",
    "\n",
    "        cov_output04 = F.relu(self.conv34(output))\n",
    "        cov_output04 = cov_output04.permute(0, 2, 1)\n",
    "        # cov_output04 = F.max_pool1d(cov_output04, 4)\n",
    "\n",
    "        \n",
    "        # 下面是将 4 个做完 LSTM-CNN 的数据拼起来\n",
    "        output = torch.cat([cov_output01, cov_output02, cov_output03, cov_output04], 2)    # 40 x 25 x 1024 [batch_size, seq_len, dim]\n",
    "\n",
    "        \n",
    "        # 下面是将拼接后的数据输出为 1 维的预测值\n",
    "        output = self.linear_3(output)                                                # 40 x 25 x 1 [batch_size, seq_len, out_dim]\n",
    "        output = self.linear_4(output)                                                # 40 x 25 x 1 [batch_size, seq_len, out_dim]\n",
    "\n",
    "        # 这段代码将seq_len的数据压缩成1个\n",
    "        # predictions = predictions.permute(0, 2, 1)\n",
    "        # predictions = self.linear_4(predictions)\n",
    "        # predictions = predictions.permute(0, 2, 1)\n",
    "\n",
    "        return output, h2_n, c2_n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65359048-ae92-4a86-9bb5-73d14d8b52b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACC(y_hat, y_real):\n",
    "    y_real = np.array(y_real) + 1\n",
    "    y_hat = np.array(y_hat) + 1\n",
    "    percentage = 1 - np.sqrt(np.mean(np.square((y_real - y_hat) / y_real)))\n",
    "    return percentage * 100\n",
    "\n",
    "# 定义 RMSE 损失函数。因为torch没有。\n",
    "def RMSE(y_hat, y):\n",
    "    return torch.sqrt(torch.mean((y_hat-y)**2))\n",
    "\n",
    "\n",
    "# 定义 MAPE 计算函数。平均绝对百分比误差：不受量纲影响。但y接近0时受极端值影响。为（0%）表示完美模型，MAPE 大于 （100%）则表示劣质模型。\n",
    "def MAPE(y_hat, y):\n",
    "    absolute_percent_error = (torch.abs(y_hat-y)+1e-7)/(torch.abs(y)+1e-7)\n",
    "    return torch.mean(absolute_percent_error)\n",
    "\n",
    "# 定义了 R2 的计算函数。决定系数：反映因变量的全部变异能通过回归关系被自变量解释的比例。\n",
    "# R2<=1，R2为1时说明预测模型不犯任何错误；R2为0时说明预测模型等于基准模型；R2小于0说明预测模型不如基准模型，可能数据不存在任何线性关系。\n",
    "def R2(y_hat, y):\n",
    "    y_mean = torch.mean(y)\n",
    "    ss_tot = torch.sum((y - y_mean) ** 2)\n",
    "    ss_res = torch.sum((y - y_hat) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2\n",
    "\n",
    "# 定义 SMAPE 计算函数。修复了原始MAPE的缺点-它同时具有下限（0％）和上限（200％)\n",
    "def SMAPE(y_hat, y):\n",
    "    absolute_percent_error = (torch.abs(y_hat-y)+1e-7)/(torch.abs(y_hat)+torch.abs(y)+1e-7)\n",
    "    return 2.0 * torch.mean(absolute_percent_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c37614c-3797-4ce7-95a9-6f9416e9c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练 LSTM 模型 ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "\n",
    "HIDDEN_SIZE = 1024\n",
    "NUM_LAYERS = 2\n",
    "\n",
    "model = LSTMModel(input_size=train_x.shape[3], hidden_dim_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, seq_len=train_x.shape[2], output_dim_size=1).float().to(device)\n",
    "LR = 1e-6\n",
    "# loss_func = nn.MSELoss(reduction=\"mean\")\n",
    "loss_func = RMSE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a55a643b-f390-4f82-b4fb-da27b3592b8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 of 2000 epoch \t train_loss: 0.418 \t train_MAPE: 4.96% \t train_r2: -53.456 \t valid_loss: 0.373 \t valid_MAPE: 4.97% \t valid_r2: -103.631\n",
      "19 of 2000 epoch \t train_loss: 0.439 \t train_MAPE: 5.27% \t train_r2: -57.351 \t valid_loss: 0.396 \t valid_MAPE: 5.39% \t valid_r2: -142.890\n",
      "29 of 2000 epoch \t train_loss: 0.425 \t train_MAPE: 5.13% \t train_r2: -55.251 \t valid_loss: 0.464 \t valid_MAPE: 6.39% \t valid_r2: -163.211\n",
      "39 of 2000 epoch \t train_loss: 0.443 \t train_MAPE: 5.42% \t train_r2: -61.020 \t valid_loss: 0.451 \t valid_MAPE: 6.24% \t valid_r2: -145.107\n",
      "49 of 2000 epoch \t train_loss: 0.413 \t train_MAPE: 5.07% \t train_r2: -53.838 \t valid_loss: 0.464 \t valid_MAPE: 6.50% \t valid_r2: -168.267\n",
      "59 of 2000 epoch \t train_loss: 0.402 \t train_MAPE: 4.88% \t train_r2: -51.602 \t valid_loss: 0.481 \t valid_MAPE: 6.74% \t valid_r2: -184.263\n",
      "69 of 2000 epoch \t train_loss: 0.410 \t train_MAPE: 5.01% \t train_r2: -52.365 \t valid_loss: 0.414 \t valid_MAPE: 5.76% \t valid_r2: -102.940\n",
      "79 of 2000 epoch \t train_loss: 0.389 \t train_MAPE: 4.76% \t train_r2: -48.954 \t valid_loss: 0.411 \t valid_MAPE: 5.69% \t valid_r2: -134.212\n",
      "89 of 2000 epoch \t train_loss: 0.374 \t train_MAPE: 4.55% \t train_r2: -44.731 \t valid_loss: 0.478 \t valid_MAPE: 6.69% \t valid_r2: -161.893\n",
      "99 of 2000 epoch \t train_loss: 0.358 \t train_MAPE: 4.36% \t train_r2: -43.648 \t valid_loss: 0.495 \t valid_MAPE: 6.98% \t valid_r2: -178.806\n",
      "109 of 2000 epoch \t train_loss: 0.350 \t train_MAPE: 4.27% \t train_r2: -42.386 \t valid_loss: 0.454 \t valid_MAPE: 6.35% \t valid_r2: -147.665\n",
      "119 of 2000 epoch \t train_loss: 0.350 \t train_MAPE: 4.27% \t train_r2: -42.949 \t valid_loss: 0.471 \t valid_MAPE: 6.59% \t valid_r2: -139.384\n",
      "129 of 2000 epoch \t train_loss: 0.335 \t train_MAPE: 4.06% \t train_r2: -38.560 \t valid_loss: 0.455 \t valid_MAPE: 6.40% \t valid_r2: -137.954\n",
      "139 of 2000 epoch \t train_loss: 0.317 \t train_MAPE: 3.83% \t train_r2: -35.129 \t valid_loss: 0.455 \t valid_MAPE: 6.42% \t valid_r2: -132.399\n",
      "149 of 2000 epoch \t train_loss: 0.309 \t train_MAPE: 3.73% \t train_r2: -33.028 \t valid_loss: 0.469 \t valid_MAPE: 6.60% \t valid_r2: -139.254\n",
      "159 of 2000 epoch \t train_loss: 0.333 \t train_MAPE: 4.05% \t train_r2: -39.208 \t valid_loss: 0.493 \t valid_MAPE: 6.99% \t valid_r2: -148.376\n",
      "169 of 2000 epoch \t train_loss: 0.309 \t train_MAPE: 3.75% \t train_r2: -33.783 \t valid_loss: 0.463 \t valid_MAPE: 6.54% \t valid_r2: -136.138\n",
      "179 of 2000 epoch \t train_loss: 0.292 \t train_MAPE: 3.53% \t train_r2: -30.080 \t valid_loss: 0.463 \t valid_MAPE: 6.54% \t valid_r2: -119.976\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4112\\2756628498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mbatch_mape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAPE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python37\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python37\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m                    eps=group['eps'])\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\python37\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练 LSTM 模型;  ---- 这里的损失函数是计算Sequence最后一个元素的预测数据和真实数据差异\n",
    "model.train()\n",
    "epochs = 2000\n",
    "train_epoch_loss = 0\n",
    "train_epoch_loss_list = []\n",
    "train_epoch_acc_list = []\n",
    "valid_epoch_loss = 0\n",
    "valid_epoch_loss_list = []\n",
    "valid_epoch_acc_list = []\n",
    "\n",
    "train_batch_count = train_x.shape[0]\n",
    "valid_batch_count = valid_x.shape[0]\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).float().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).float().to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    batch_mape = []\n",
    "    batch_r2   = []\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_mape = 0\n",
    "    train_epoch_r2 = 0\n",
    "    train_pred_value_list = []\n",
    "    train_real_value_list = []\n",
    "    train_batch_list = list(range(0, train_batch_count))\n",
    "    # random.shuffle(train_batch_list)\n",
    "    for step in train_batch_list:\n",
    "        train_pred, hn, cn = model(train_x[step], h0, c0)                                                    # pred: [batch_size, seq_len, out_dim]  但被修改成了 [batch_size, 1, out_dim]\n",
    "        loss = loss_func(train_pred[:, -1, -1], train_y[step][:, -1, -1])                                    # 取batch里每个sequence最后一个预测输出来和实际\n",
    "        train_pred_value_list.extend(list(train_pred[:, -1, -1].cpu().detach().flatten().numpy() ))\n",
    "        train_real_value_list.extend(list(train_y[step][:, -1, -1].cpu().detach().flatten().numpy() ))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.cpu().data.numpy())\n",
    "        batch_mape.append(MAPE(train_pred[:, -1, -1], train_y[step][:, -1, -1]).item())\n",
    "        batch_r2.append(R2(train_pred[:, -1, -1], train_y[step][:, -1, -1]).item())\n",
    "    # print(batch_mape)\n",
    "    train_epoch_loss = np.mean(batch_loss)\n",
    "    train_epoch_mape = np.mean(batch_mape)\n",
    "    train_epoch_r2 = np.mean(batch_r2)\n",
    "\n",
    "    batch_loss = []\n",
    "    batch_mape = []\n",
    "    batch_r2 = []\n",
    "    valid_epoch_loss = 0\n",
    "    valid_epoch_mape = 0\n",
    "    valid_epoch_r2 = 0\n",
    "    valid_pred_value_list = []\n",
    "    valid_real_value_list = []\n",
    "    for step in range(valid_batch_count):\n",
    "        valid_pred, hn, cn = model(valid_x[step], h0, c0)\n",
    "        loss = loss_func(valid_pred[:, -1, -1], valid_y[step][:, -1, -1])\n",
    "        valid_pred_value_list.extend(list(valid_pred[:, -1, -1].cpu().detach().flatten().numpy()))\n",
    "        valid_real_value_list.extend(list(valid_y[step][ :, -1, -1].cpu().detach().flatten().numpy()))\n",
    "        batch_loss.append(loss.cpu().data.numpy())\n",
    "        batch_mape.append(MAPE(valid_pred[:, -1, -1], valid_y[step][:, -1, -1]).item())\n",
    "        batch_r2.append(R2(valid_pred[:, -1, -1], valid_y[step][:, -1, -1]).item())\n",
    "    # print(batch_loss)\n",
    "    valid_epoch_loss = np.mean(batch_loss)\n",
    "    valid_epoch_mape = np.mean(batch_mape)\n",
    "    valid_epoch_r2 = np.mean(batch_r2)\n",
    "\n",
    "\n",
    "    valid_epoch_loss_list.append(valid_epoch_loss)\n",
    "    train_epoch_loss_list.append(train_epoch_loss)\n",
    "\n",
    "    if ((epoch+1) % 10) == 0:\n",
    "        print(\"{} of {} epoch \\t train_loss: {:.3f} \\t train_MAPE: {:.2%} \\t train_r2: {:.3f} \\t valid_loss: {:.3f} \\t valid_MAPE: {:.2%} \\t valid_r2: {:.3f}\".format(epoch, epochs, train_epoch_loss, train_epoch_mape, train_epoch_r2, valid_epoch_loss, valid_epoch_mape, valid_epoch_r2))\n",
    "\n",
    "    if train_epoch_loss < 0.1:\n",
    "        print(\"{} of {} epoch \\t train_loss: {:.3f} \\t train_MAPE: {:.2%} \\t train_r2: {:.3f} \\t valid_loss: {:.3f} \\t valid_MAPE: {:.2%} \\t valid_r2: {:.3f}\".format(epoch, epochs, train_epoch_loss, train_epoch_mape, train_epoch_r2, valid_epoch_loss, valid_epoch_mape, valid_epoch_r2))\n",
    "        print(\"****************************************** STOP TRAIN  ****************************************\")\n",
    "        break\n",
    "\n",
    "plt.plot(train_epoch_loss_list, 'r-')\n",
    "plt.plot(valid_epoch_loss_list, 'b-')\n",
    "plt.show()\n",
    "print(\"min train loss: {:.3f}\".format(min(train_epoch_loss_list)))\n",
    "print(\"min valid loss: {:.3f}\".format(min(valid_epoch_loss_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69845d-ab88-441a-8ad9-e92ddf92884f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 这是 train 的预测图形\n",
    "plt.plot(train_real_value_list, 'r-')\n",
    "plt.plot(train_pred_value_list, 'b-')\n",
    "plt.show()\n",
    "# print(train_real_value_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5eeb65-91d9-40f2-a653-2a0d84653eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 这是 vali的预测图形\n",
    "plt.plot(valid_real_value_list, 'r-')\n",
    "plt.plot(valid_pred_value_list, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc4f28-b980-401f-873d-95218a9cd9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 这是 valid 最后一段的数据。误差累积到这里已经很大了。\n",
    "plt.plot(valid_y[-1,:,-1,-1].cpu().detach().flatten().numpy(), 'r-')\n",
    "plt.plot(valid_pred[:,-1].cpu().detach().flatten().numpy(), 'b-')\n",
    "plt.show()\n",
    "print(valid_y[-1,:,-1,-1].cpu().detach().flatten().numpy())\n",
    "print(valid_pred[:,-1].cpu().detach().flatten().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15059b8c-5221-47e4-8716-374496178915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用模型预测数据\n",
    "# 考虑到时序因素，这里的时候误差很大。\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, test_x.shape[1], HIDDEN_SIZE).float().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, test_x.shape[1], HIDDEN_SIZE).float().to(device)\n",
    "\n",
    "for step in range(test_x.shape[0]):\n",
    "    pred, hn, cn = model(test_x[step], h0, c0)\n",
    "    \n",
    "    loss = loss_func(pred[:,-1,-1], test_y[step][:,-1,-1])               # Compare the all sequences' last element in one batch\n",
    "    \n",
    "    if test_x.shape[0] > 1:\n",
    "        actual_line.append(test_y[step][-1,-1].item())\n",
    "        pred_line.append(pred[-1,-1].item())\n",
    "    elif test_x.shape[0] == 1:\n",
    "        actual_line = test_y[step].cpu().detach().flatten().numpy()        # Only plot the last sequence of test batch\n",
    "        pred_line   = pred[:,-1].cpu().detach().flatten().numpy()                # Only plot the last sequence of test batch\n",
    "        \n",
    "print(\"Test Loss : {:.3f}\".format(loss.data))\n",
    "print(\"Test Prediction: {:.2f}\".format(float(pred[-1,-1].data)))\n",
    "print(\"Test Actual:     {:.2f}\".format(float(test_y[step][-1,-1].data)))\n",
    "\n",
    "\n",
    "plt.plot(test_y[step,:,-1,-1].cpu().detach().flatten().numpy(), 'r--')\n",
    "plt.plot(pred[:,-1].cpu().detach().flatten().numpy(), 'b-')\n",
    "plt.show()\n",
    "print(test_y[step,:,-1,-1])\n",
    "print(pred[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1c0fe-d7bc-4558-a152-f7f432903458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把rolling_data再分割为 train / test 就再预测\n",
    "# 既然 预测值 和时序相关性很高，可以考虑太早的零星数据对于test影响不大，可以删掉\n",
    "rolling_data = pd.DataFrame()\n",
    "for i in dataset.rolling(SEQ_LENGTH):\n",
    "    if i.shape[0] == SEQ_LENGTH:\n",
    "        rolling_data = rolling_data.append(i)\n",
    "\n",
    "rolling_data = rolling_data.values.reshape(-1, SEQ_LENGTH, X_DIM+Y_SEQ_LEN)                   # 数据一共是 seq_count x seq_len x (x_in_dim+Y_SEQ_LEN) \n",
    "\n",
    "# 打乱train数据\n",
    "# tmp_data = rolling_data[:-1]\n",
    "# np.random.shuffle(tmp_data)\n",
    "# rolling_data = np.concatenate((tmp_data, rolling_data[-1:]), axis=0)\n",
    "\n",
    "\n",
    "print(rolling_data.shape)\n",
    "print(TRAIN_BATCH_SIZE)\n",
    "print(((rolling_data.shape[0]-1)//TRAIN_BATCH_SIZE)*TRAIN_BATCH_SIZE)\n",
    "rolling_data = rolling_data[-((rolling_data.shape[0]-1)//TRAIN_BATCH_SIZE)*TRAIN_BATCH_SIZE-1:,]\n",
    "print(rolling_data.shape)\n",
    "\n",
    "train = rolling_data[:-1].reshape(-1, TRAIN_BATCH_SIZE, SEQ_LENGTH, X_DIM+Y_DIM*Y_SEQ_LEN)                    # 把数据转成 tain_batch_count x TRAIN_BATCH_SIZE x seq_len x in_dim 格式\n",
    "test  = rolling_data[-1:].reshape(1, 1, SEQ_LENGTH, X_DIM+Y_DIM*Y_SEQ_LEN)                     # 把数据转成 test_batch_count x TEST_BATCH_SIZE x seq_len x in_dim 格式\n",
    "\n",
    "train = torch.tensor(train).to(device)\n",
    "test  = torch.tensor(test).to(device)\n",
    "\n",
    "train_x, train_y = train[:,:,:,Y_SEQ_LEN:], train[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "test_x,  test_y  = test[:,:,:, Y_SEQ_LEN:],  test[:,:,-1:,0:Y_SEQ_LEN]           # [train_batch_count, batch_size, sequence_length, XorY dimission]\n",
    "print(train_x.shape, train_y.shape)\n",
    "print(test_x.shape, test_y.shape)\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0316ed-0aa1-481d-9101-cbb51edb191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再重新生成模型再 train 模型\n",
    "model = LSTMModel(input_size=train_x.shape[3], hidden_dim_size=HIDDEN_SIZE, num_layers=NUM_LAYERS, seq_len=train_x.shape[2], output_dim_size=1).float().to(device)\n",
    "LR = 1e-4\n",
    "# loss_func = nn.MSELoss(reduction=\"mean\")\n",
    "loss_func = RMSE\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-6)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=1, last_epoch=-1)\n",
    "model.train()\n",
    "epochs = 200\n",
    "\n",
    "train_epoch_loss_list = []\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).float().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, TRAIN_BATCH_SIZE, HIDDEN_SIZE).float().to(device)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch_loss = []\n",
    "    batch_mape = []\n",
    "    batch_r2   = []\n",
    "    train_epoch_loss = 0\n",
    "    train_pred_value_list = []\n",
    "    train_real_value_list = []\n",
    "    train_batch_list = list(range(0, train_batch_count))\n",
    "    # random.shuffle(train_batch_list)\n",
    "    for step in range(0, train_x.shape[0]):\n",
    "        train_pred, hn, cn = model(train_x[step], h0, c0)\n",
    "        loss = loss_func(train_pred[:,-1,-1], train_y[step][:,-1,-1])                # Compare the all sequences' last element in one batch\n",
    "        train_pred_value_list.extend(list(train_pred[:,-1,-1].cpu().detach().flatten().numpy() ))\n",
    "        train_real_value_list.extend(list(train_y[step,:,-1,-1].cpu().detach().flatten().numpy() ))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=20, norm_type=2)\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.cpu().data.numpy())\n",
    "        batch_mape.append(MAPE(train_pred[:, -1, -1], train_y[step][:, -1, -1]).item())\n",
    "        batch_r2.append(R2(train_pred[:, -1, -1], train_y[step][:, -1, -1]).item())\n",
    "    train_epoch_loss_list.append(np.mean(batch_loss))\n",
    "\n",
    "    if ((epoch+1) % 10) == 0:\n",
    "        print(\"{} of {} epoch \\t train_loss: {:.3f} \\t train_MAPE: {:.2%} \\t train_r2: {:.3f}\".format(epoch, epochs, np.mean(batch_loss), np.mean(batch_mape), np.mean(batch_r2)))\n",
    "\n",
    "    if np.mean(batch_loss)<0.05:\n",
    "        print(\"{} of {} epoch got the smallest epoch train loss: {:.3f}\".format(epoch, epochs, np.mean(batch_loss)))\n",
    "        break\n",
    "\n",
    "plt.plot(train_real_value_list, 'r-')\n",
    "plt.plot(train_pred_value_list, 'b-')\n",
    "plt.show()\n",
    "print(\"min train loss: {:.3f}\".format(min(train_epoch_loss_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab2e6de-1c6b-4dab-9f1f-429949057b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_pred.shape)\n",
    "print(train_y.shape)\n",
    "\n",
    "print(train_y[-1,-1])\n",
    "print(train_pred[-1,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336190a-8bc4-47c5-975a-8bd2686a62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(valid_real_value_list, 'r-')\n",
    "plt.plot(valid_pred_value_list, 'b-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5edd6-7cd8-400f-b198-2d8cdfa405ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_x.shape)\n",
    "# print(test_x.shape)\n",
    "print(train_real_value_list[-1])\n",
    "print(train_pred_value_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfbfe06-2838-4e89-a7be-69dc7d233231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "h0 = torch.zeros(NUM_LAYERS, test_x.shape[1], HIDDEN_SIZE).float().to(device)\n",
    "c0 = torch.zeros(NUM_LAYERS, test_x.shape[1], HIDDEN_SIZE).float().to(device)\n",
    "\n",
    "pred, hn, cn = model(test_x[-1], h0, c0)\n",
    "\n",
    "print(test_y.shape)\n",
    "print(pred.shape)\n",
    "print(\"Real: {:.2f}\".format(test_y.item()))\n",
    "print(\"Pred: {:.2f}\".format(pred[:,-1,:].item()))\n",
    "\n",
    "loss = loss_func(pred[:,-1,-1], test_y[-1][:,-1,-1])\n",
    "print(\"loss: {:.3f}\".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884f1968-b9a4-4cf7-9bcc-4b7436a7e403",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model, 'e:\\\\Model_601229_qfq.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372fbebb-5056-462f-99c4-68e777652903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
